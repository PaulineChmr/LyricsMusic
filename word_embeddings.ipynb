{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric Mood Classification - Word Embeddings\n",
    "\n",
    "The majority of the code used in this workbook can be found in `lyrics2vec.py`.\n",
    "\n",
    "The notebook is split into two parts:\n",
    "\n",
    "1. Lyrics & Vocabulary Working Examples\n",
    "2. Tensorflow & Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jcworkma/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jcworkma/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Project Imports\n",
    "from scrape_lyrics import configure_logging, logger\n",
    "from index_lyrics import read_file_contents\n",
    "import lyrics2vec\n",
    "\n",
    "# Python and Package Imports\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "import datetime\n",
    "import random\n",
    "import string\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "\n",
    "# NLTK materials - make sure that you have stopwords and punkt\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# setup logging\n",
    "configure_logging(logname='lyrics2vec_notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics & Vocabulary Working Examples\n",
    "### How many unique words do we have?\n",
    "\n",
    "We begin by tackling this question as an exercise to familiarize ourselves with accessing and reading the lyrics and building a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/294299 lyric files processed. 0.00 minutes elapsed. 0 contents processed. 0 unique words acquired.\n",
      "10000/294299 lyric files processed. 0.01 minutes elapsed. 9547 contents processed. 122479 unique words acquired.\n",
      "20000/294299 lyric files processed. 0.02 minutes elapsed. 19145 contents processed. 195130 unique words acquired.\n",
      "30000/294299 lyric files processed. 0.03 minutes elapsed. 28736 contents processed. 257393 unique words acquired.\n",
      "40000/294299 lyric files processed. 0.04 minutes elapsed. 38320 contents processed. 308552 unique words acquired.\n",
      "50000/294299 lyric files processed. 0.05 minutes elapsed. 47911 contents processed. 357693 unique words acquired.\n",
      "60000/294299 lyric files processed. 0.06 minutes elapsed. 57519 contents processed. 402886 unique words acquired.\n",
      "70000/294299 lyric files processed. 0.07 minutes elapsed. 67117 contents processed. 446049 unique words acquired.\n",
      "80000/294299 lyric files processed. 0.08 minutes elapsed. 76664 contents processed. 484761 unique words acquired.\n",
      "90000/294299 lyric files processed. 0.09 minutes elapsed. 86238 contents processed. 523551 unique words acquired.\n",
      "100000/294299 lyric files processed. 0.10 minutes elapsed. 95793 contents processed. 559187 unique words acquired.\n",
      "110000/294299 lyric files processed. 0.11 minutes elapsed. 105391 contents processed. 594497 unique words acquired.\n",
      "120000/294299 lyric files processed. 0.12 minutes elapsed. 114962 contents processed. 627482 unique words acquired.\n",
      "130000/294299 lyric files processed. 0.13 minutes elapsed. 124552 contents processed. 660732 unique words acquired.\n",
      "140000/294299 lyric files processed. 0.14 minutes elapsed. 134145 contents processed. 692278 unique words acquired.\n",
      "150000/294299 lyric files processed. 0.15 minutes elapsed. 143727 contents processed. 724343 unique words acquired.\n",
      "160000/294299 lyric files processed. 0.16 minutes elapsed. 153261 contents processed. 754730 unique words acquired.\n",
      "170000/294299 lyric files processed. 0.17 minutes elapsed. 162819 contents processed. 783273 unique words acquired.\n",
      "180000/294299 lyric files processed. 0.18 minutes elapsed. 172393 contents processed. 809591 unique words acquired.\n",
      "190000/294299 lyric files processed. 0.19 minutes elapsed. 181982 contents processed. 837658 unique words acquired.\n",
      "200000/294299 lyric files processed. 0.20 minutes elapsed. 191524 contents processed. 865905 unique words acquired.\n",
      "210000/294299 lyric files processed. 0.21 minutes elapsed. 201096 contents processed. 892760 unique words acquired.\n",
      "220000/294299 lyric files processed. 0.22 minutes elapsed. 210674 contents processed. 918515 unique words acquired.\n",
      "230000/294299 lyric files processed. 0.23 minutes elapsed. 220261 contents processed. 944771 unique words acquired.\n",
      "240000/294299 lyric files processed. 0.24 minutes elapsed. 229819 contents processed. 969901 unique words acquired.\n",
      "250000/294299 lyric files processed. 0.25 minutes elapsed. 239386 contents processed. 993682 unique words acquired.\n",
      "260000/294299 lyric files processed. 0.26 minutes elapsed. 248957 contents processed. 1017986 unique words acquired.\n",
      "270000/294299 lyric files processed. 0.27 minutes elapsed. 258530 contents processed. 1041076 unique words acquired.\n",
      "280000/294299 lyric files processed. 0.28 minutes elapsed. 268134 contents processed. 1065321 unique words acquired.\n",
      "290000/294299 lyric files processed. 0.29 minutes elapsed. 277706 contents processed. 1090218 unique words acquired.\n",
      "Elapsed Time: 0.2931053082148234 minutes.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "unique_words = collections.defaultdict(lambda: 0)\n",
    "lyricfiles = os.listdir(lyrics2vec.LYRICS_TXT_DIR)\n",
    "num_files = len(lyricfiles)\n",
    "contents_processed = 0\n",
    "\n",
    "for count, lyricfile in enumerate(lyricfiles):\n",
    "\n",
    "    # progress update\n",
    "    if count % 10000 == 0:\n",
    "        print('{0}/{1} lyric files processed. {2:.02f} minutes elapsed. {3} contents processed. {4} unique words acquired.'.format(\n",
    "            count, num_files, (time.time() - start) / 60, contents_processed, len(unique_words)))\n",
    "\n",
    "    # read contents and look for unique words    \n",
    "    lyricfile = os.path.join(lyrics2vec.LYRICS_TXT_DIR, lyricfile)\n",
    "    contents = read_file_contents(lyricfile)\n",
    "    if contents and contents[0]:\n",
    "        split = contents[0].split()\n",
    "        for word in split:\n",
    "            unique_words[word] += 1\n",
    "        contents_processed += 1\n",
    "            \n",
    "end = time.time()\n",
    "elapsed = (end - start) / 60\n",
    "\n",
    "print('Elapsed Time: {0} minutes.'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique Words: 1099635\n"
     ]
    }
   ],
   "source": [
    "print('Number of Unique Words: {0}'.format(len(unique_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the most common words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1888745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>1607271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1313028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>1119509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1003483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>me</th>\n",
       "      <td>748343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>704609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>my</th>\n",
       "      <td>614638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in</th>\n",
       "      <td>613737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>582333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it</th>\n",
       "      <td>510154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And</th>\n",
       "      <td>497584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>460351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>on</th>\n",
       "      <td>409884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'm</th>\n",
       "      <td>387302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>383197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is</th>\n",
       "      <td>372311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be</th>\n",
       "      <td>337014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>326832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>312369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "the   1888745\n",
       "I     1607271\n",
       "you   1313028\n",
       "to    1119509\n",
       "a     1003483\n",
       "me     748343\n",
       "and    704609\n",
       "my     614638\n",
       "in     613737\n",
       "of     582333\n",
       "it     510154\n",
       "And    497584\n",
       "your   460351\n",
       "on     409884\n",
       "I'm    387302\n",
       "that   383197\n",
       "is     372311\n",
       "be     337014\n",
       "for    326832\n",
       "all    312369"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import words into a pandas dataframe and display top N words\n",
    "df = pd.DataFrame.from_dict(unique_words, orient='index', columns=['count'])\n",
    "df = df.sort_values('count', ascending=False)\n",
    "df[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow & Word2vec\n",
    "\n",
    "To generate our word embeddings, we make use of the word2vec model as defined by [Mikolov et al](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf) and the [implementation provided by TensorFlow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py).\n",
    "\n",
    "We also utilized the following sources to provide more background and direction:\n",
    "* http://adventuresinmachinelearning.com/word2vec-tutorial-tensorflow/\n",
    "* https://www.tensorflow.org/tutorials/representation/word2vec\n",
    "* https://github.com/PacktPublishing/TensorFlow-Machine-Learning-Cookbook/blob/master/Chapter%2007/doc2vec.py\n",
    "* https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-11-cnn-word2vec-41f5e28eda74\n",
    "\n",
    "Roughly, the steps we followed are\n",
    "\n",
    "1. Preprocess Lyrics\n",
    "2. Build Vocabulary\n",
    "3. Construct Dataset\n",
    "4. Train Model\n",
    "\n",
    "Our model and most of the supporting code can be found in the _lyrics2vec_ class in `lyrics2vec.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the Lyrics\n",
    "\n",
    "First, when reading in the lyrics, there is some amount of preprocessing we must do to make the words more machine friendly. For our preprocessing, we\n",
    "\n",
    "1. Remove all stopwords\n",
    "2. Remove all punctuation\n",
    "3. Lowercase everything\n",
    "4. Perform tokenization with NLTK's word_tokenize function\n",
    "\n",
    "Below is an example of the output of the preprocessing. Note how contractions and certain slang words like 'wanna' are split. This is because these entities are handled as two different words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: I don't wanna die I sometimes wish I'd never been born at all\n",
      "After: [\"n't\", 'wan', 'na', 'die', 'sometimes', 'wish', \"'d\", 'never', 'born']\n"
     ]
    }
   ],
   "source": [
    "s = \"I don't wanna die I sometimes wish I'd never been born at all\"\n",
    "print('Before: {0}\\nAfter: {1}'.format(s, lyrics2vec.lyrics_preprocessing(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Vocabulary\n",
    "\n",
    "We begin by initializing the lyrics2vec class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vectorizer = lyrics2vec.lyrics2vec()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the extract_words function to loop through all of the lyric txt files, apply the lyrics_preprocessing function, and append all tokens to a growing list.\n",
    "\n",
    "The list is saved to a file. The core one for this project being `logs/tf/vocabulary.txt` but the extract_words function can accept any abritrary words file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 08:35:23,531 - INFO: No word_file provided. Creating new word file at logs/tf/vocabulary.txt.\n",
      "2018-11-25 08:35:23,711 - DEBUG: 0/294299 lyric files processed. 0.00 minutes elapsed. 0 contents processed. 0 words acquired.\n",
      "2018-11-25 08:35:35,271 - DEBUG: 10000/294299 lyric files processed. 0.20 minutes elapsed. 9547 contents processed. 1259791 words acquired.\n",
      "2018-11-25 08:35:46,964 - DEBUG: 20000/294299 lyric files processed. 0.39 minutes elapsed. 19145 contents processed. 2515120 words acquired.\n",
      "2018-11-25 08:35:58,796 - DEBUG: 30000/294299 lyric files processed. 0.59 minutes elapsed. 28736 contents processed. 3779741 words acquired.\n",
      "2018-11-25 08:36:10,394 - DEBUG: 40000/294299 lyric files processed. 0.78 minutes elapsed. 38320 contents processed. 5016148 words acquired.\n",
      "2018-11-25 08:36:22,229 - DEBUG: 50000/294299 lyric files processed. 0.98 minutes elapsed. 47911 contents processed. 6281925 words acquired.\n",
      "2018-11-25 08:36:33,928 - DEBUG: 60000/294299 lyric files processed. 1.17 minutes elapsed. 57519 contents processed. 7538992 words acquired.\n",
      "2018-11-25 08:36:45,856 - DEBUG: 70000/294299 lyric files processed. 1.37 minutes elapsed. 67117 contents processed. 8816560 words acquired.\n",
      "2018-11-25 08:36:57,600 - DEBUG: 80000/294299 lyric files processed. 1.57 minutes elapsed. 76664 contents processed. 10063517 words acquired.\n",
      "2018-11-25 08:37:09,394 - DEBUG: 90000/294299 lyric files processed. 1.76 minutes elapsed. 86238 contents processed. 11319728 words acquired.\n",
      "2018-11-25 08:37:21,087 - DEBUG: 100000/294299 lyric files processed. 1.96 minutes elapsed. 95793 contents processed. 12568244 words acquired.\n",
      "2018-11-25 08:37:32,831 - DEBUG: 110000/294299 lyric files processed. 2.15 minutes elapsed. 105391 contents processed. 13816340 words acquired.\n",
      "2018-11-25 08:37:44,470 - DEBUG: 120000/294299 lyric files processed. 2.35 minutes elapsed. 114962 contents processed. 15057168 words acquired.\n",
      "2018-11-25 08:37:56,228 - DEBUG: 130000/294299 lyric files processed. 2.54 minutes elapsed. 124552 contents processed. 16318834 words acquired.\n",
      "2018-11-25 08:38:07,959 - DEBUG: 140000/294299 lyric files processed. 2.74 minutes elapsed. 134145 contents processed. 17573724 words acquired.\n",
      "2018-11-25 08:38:19,709 - DEBUG: 150000/294299 lyric files processed. 2.94 minutes elapsed. 143727 contents processed. 18823535 words acquired.\n",
      "2018-11-25 08:38:31,469 - DEBUG: 160000/294299 lyric files processed. 3.13 minutes elapsed. 153261 contents processed. 20075379 words acquired.\n",
      "2018-11-25 08:38:44,054 - DEBUG: 170000/294299 lyric files processed. 3.34 minutes elapsed. 162819 contents processed. 21319576 words acquired.\n",
      "2018-11-25 08:39:00,766 - DEBUG: 180000/294299 lyric files processed. 3.62 minutes elapsed. 172393 contents processed. 22565685 words acquired.\n",
      "2018-11-25 08:39:16,900 - DEBUG: 190000/294299 lyric files processed. 3.89 minutes elapsed. 181982 contents processed. 23828593 words acquired.\n",
      "2018-11-25 08:39:33,514 - DEBUG: 200000/294299 lyric files processed. 4.17 minutes elapsed. 191524 contents processed. 25083660 words acquired.\n",
      "2018-11-25 08:39:50,121 - DEBUG: 210000/294299 lyric files processed. 4.44 minutes elapsed. 201096 contents processed. 26344763 words acquired.\n",
      "2018-11-25 08:40:06,813 - DEBUG: 220000/294299 lyric files processed. 4.72 minutes elapsed. 210674 contents processed. 27602407 words acquired.\n",
      "2018-11-25 08:40:23,328 - DEBUG: 230000/294299 lyric files processed. 5.00 minutes elapsed. 220261 contents processed. 28858963 words acquired.\n",
      "2018-11-25 08:40:39,939 - DEBUG: 240000/294299 lyric files processed. 5.27 minutes elapsed. 229819 contents processed. 30128777 words acquired.\n",
      "2018-11-25 08:40:55,808 - DEBUG: 250000/294299 lyric files processed. 5.54 minutes elapsed. 239386 contents processed. 31369940 words acquired.\n",
      "2018-11-25 08:41:12,418 - DEBUG: 260000/294299 lyric files processed. 5.81 minutes elapsed. 248957 contents processed. 32620557 words acquired.\n",
      "2018-11-25 08:41:28,848 - DEBUG: 270000/294299 lyric files processed. 6.09 minutes elapsed. 258530 contents processed. 33862252 words acquired.\n",
      "2018-11-25 08:41:45,263 - DEBUG: 280000/294299 lyric files processed. 6.36 minutes elapsed. 268134 contents processed. 35122438 words acquired.\n",
      "2018-11-25 08:42:01,712 - DEBUG: 290000/294299 lyric files processed. 6.64 minutes elapsed. 277706 contents processed. 36370991 words acquired.\n",
      "2018-11-25 08:42:08,522 - INFO: Saving words to file logs/tf/vocabulary.txt\n",
      "2018-11-25 08:42:16,240 - INFO: 36906526 words found\n",
      "2018-11-25 08:42:16,240 - INFO: First 10 words:\n",
      "[\"'s\", 'taken', 'long', 'see', \"'ve\", 'wrong', 'see', \"'d\", 'gone', 'today']\n",
      "2018-11-25 08:42:16,241 - INFO: Elapsed Time: 6.878495792547862 minutes.\n"
     ]
    }
   ],
   "source": [
    "words = lyrics_vectorizer.extract_words(\n",
    "    preprocessing_func=lyrics2vec.lyrics_preprocessing,\n",
    "    root_dir=lyrics2vec.LYRICS_TXT_DIR,\n",
    "    words_file=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36906526 words found\n",
      "First 10 words:\n",
      "[\"'s\", 'taken', 'long', 'see', \"'ve\", 'wrong', 'see', \"'d\", 'gone', 'today']\n"
     ]
    }
   ],
   "source": [
    "print('{0} words found'.format(len(words)))\n",
    "print('First {0} words:\\n{1}'.format(10, words[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Dataset From Vocabulary\n",
    "\n",
    "With the preprocessed vocabulary in hand, we are ready to build the dataset. The dataset will consist of four entities:\n",
    "\n",
    "* count: a dictionary that maps each unique token to its int num of occurences in the dataset\n",
    "* dictionary: a dictionary that maps each token to its int id\n",
    "* reversed_dictionary: a dictionary maps each int id to its token\n",
    "* data: a list of integer ids in order for all tokens in the dataset\n",
    "\n",
    "These four entities can be used in conjuction with one another to find, for example, a word given an integer id or vice versa or the number of times a word occurs in the dataset. They are all stored as data members of the lyrics2vec class as they are frequently referenced by the model itself.\n",
    "\n",
    "In an effort to not be weighted down by the more obscure words in the vocabulary, we've elected to maintain only the top 50,000 words in the vocabulary. The rest will be denoted as 'UNK'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_vectorizer.build_dataset(lyrics2vec.VOCAB_SIZE, words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the words dictionary is no longer necessary. We remove it to free up memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory footprint is probably getting pretty large...\n",
    "# remove unneeded 'words'\n",
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are some numbers and examples from the output of build_dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of count: 50000\n",
      "count[:5]: [['UNK', 1697931], (\"'s\", 752206), (\"n't\", 698683), (\"'m\", 402884), ('love', 310636)]\n",
      "\n",
      "Length of dictionary: 50000\n",
      "dictionary[\"hello\"]: 805\n",
      "dictionary[\"world\"]: 49\n",
      "\n",
      "Length of reversed_dictionary: 50000\n",
      "reversed_dictionary[805]: hello\n",
      "reversed_dictionary[49]: world\n",
      "\n",
      "Length of data: 36906526\n",
      "data[:5]: [1, 893, 70, 17, 15]\n",
      "reversed_dictionary[data[:5]]: [\"'s\", 'taken', 'long', 'see', \"'ve\"]\n"
     ]
    }
   ],
   "source": [
    "print('Length of count: {0}'.format(len(lyrics_vectorizer.count)))\n",
    "print('count[:5]: {0}'.format(lyrics_vectorizer.count[:5]))\n",
    "print()\n",
    "print('Length of dictionary: {0}'.format(len(lyrics_vectorizer.dictionary)))\n",
    "print('dictionary[\"hello\"]: {0}'.format(lyrics_vectorizer.dictionary['hello']))\n",
    "print('dictionary[\"world\"]: {0}'.format(lyrics_vectorizer.dictionary['world']))\n",
    "print()\n",
    "print('Length of reversed_dictionary: {0}'.format(len(lyrics_vectorizer.reversed_dictionary)))\n",
    "print('reversed_dictionary[805]: {0}'.format(lyrics_vectorizer.reversed_dictionary[805]))\n",
    "print('reversed_dictionary[49]: {0}'.format(lyrics_vectorizer.reversed_dictionary[49]))\n",
    "print()\n",
    "print('Length of data: {0}'.format(len(lyrics_vectorizer.data)))\n",
    "print('data[:5]: {0}'.format(lyrics_vectorizer.data[:5]))\n",
    "l = list()\n",
    "for word_id in lyrics_vectorizer.data[:5]:\n",
    "    l.append(lyrics_vectorizer.reversed_dictionary[word_id])\n",
    "print('reversed_dictionary[data[:5]]: {0}'.format(l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "406 thinking -> 74 find\n",
      "406 thinking -> 304 tears\n",
      "113 another -> 406 thinking\n",
      "113 another -> 74 find\n",
      "41 man -> 74 find\n",
      "41 man -> 304 tears\n",
      "249 today -> 304 tears\n",
      "249 today -> 245 seen\n"
     ]
    }
   ],
   "source": [
    "batch, labels = lyrics_vectorizer._generate_batch(\n",
    "    lyrics_vectorizer.data,\n",
    "    batch_size=8,\n",
    "    num_skips=2,\n",
    "    skip_window=4)\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print(batch[i], lyrics_vectorizer.reversed_dictionary[batch[i]], '->', labels[i, 0],\n",
    "        lyrics_vectorizer.reversed_dictionary[labels[i, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:17:22,351 - INFO: Building lyrics2vec graph\n",
      "2018-11-25 10:17:22,351 - INFO: Building lyrics2vec graph\n",
      "2018-11-25 10:17:22,354 - INFO: V=50000, batch_size=128, embedding_size=300, skip_window=4, num_skips=2, num_sampled=2\n",
      "2018-11-25 10:17:22,354 - INFO: V=50000, batch_size=128, embedding_size=300, skip_window=4, num_skips=2, num_sampled=2\n",
      "2018-11-25 10:17:22,548 - INFO: Beginning graph training\n",
      "2018-11-25 10:17:22,548 - INFO: Beginning graph training\n",
      "2018-11-25 10:17:22,639 - INFO: Initialized\n",
      "2018-11-25 10:17:22,639 - INFO: Initialized\n",
      "2018-11-25 10:17:22,683 - DEBUG: Average loss at step 0: 271.61688232421875\n",
      "2018-11-25 10:17:22,683 - DEBUG: Average loss at step 0: 271.61688232421875\n",
      "2018-11-25 10:17:22,684 - DEBUG: Time Elapsed: 0.0022478262583414716 minutes\n",
      "2018-11-25 10:17:22,684 - DEBUG: Time Elapsed: 0.0022478262583414716 minutes\n",
      "2018-11-25 10:17:22,724 - DEBUG: Nearest to 1: dann, kauniin, attending, zon, qu'aujourd'hui, common, policia, snow,\n",
      "2018-11-25 10:17:22,724 - DEBUG: Nearest to 1: dann, kauniin, attending, zon, qu'aujourd'hui, common, policia, snow,\n",
      "2018-11-25 10:17:22,730 - DEBUG: Nearest to well: ne, nema, banged, body, concerned, dina, bullshit, tuna,\n",
      "2018-11-25 10:17:22,730 - DEBUG: Nearest to well: ne, nema, banged, body, concerned, dina, bullshit, tuna,\n",
      "2018-11-25 10:17:22,735 - DEBUG: Nearest to heart: endlessly, 'so, dented, salon, annan, niqué, spell, inmensidad,\n",
      "2018-11-25 10:17:22,735 - DEBUG: Nearest to heart: endlessly, 'so, dented, salon, annan, niqué, spell, inmensidad,\n",
      "2018-11-25 10:17:22,740 - DEBUG: Nearest to life: j'dois, cigarro, ventaja, haré, cheio, esfrega, innovate, manquent,\n",
      "2018-11-25 10:17:22,740 - DEBUG: Nearest to life: j'dois, cigarro, ventaja, haré, cheio, esfrega, innovate, manquent,\n",
      "2018-11-25 10:17:22,745 - DEBUG: Nearest to 're: liever, andati, i'ts, uncertain, 'twill, rubin, retards, acabará,\n",
      "2018-11-25 10:17:22,745 - DEBUG: Nearest to 're: liever, andati, i'ts, uncertain, 'twill, rubin, retards, acabará,\n",
      "2018-11-25 10:17:22,750 - DEBUG: Nearest to la: schotter, capturing, comrade, plays, fiets, drømme, farväl, rob,\n",
      "2018-11-25 10:17:22,750 - DEBUG: Nearest to la: schotter, capturing, comrade, plays, fiets, drømme, farväl, rob,\n",
      "2018-11-25 10:17:22,754 - DEBUG: Nearest to wan: themself, ligero, havet, baigne, cuddle, probe, aves, uniqua,\n",
      "2018-11-25 10:17:22,754 - DEBUG: Nearest to wan: themself, ligero, havet, baigne, cuddle, probe, aves, uniqua,\n",
      "2018-11-25 10:17:22,759 - DEBUG: Nearest to en: radioactive, gro, jämt, riitä, hat, ichi, stoppin', acordo,\n",
      "2018-11-25 10:17:22,759 - DEBUG: Nearest to en: radioactive, gro, jämt, riitä, hat, ichi, stoppin', acordo,\n",
      "2018-11-25 10:17:22,763 - DEBUG: Nearest to cause: cares, bullseye, four-letter, ninety-seven, klem, heutzutage, aries, callo,\n",
      "2018-11-25 10:17:22,763 - DEBUG: Nearest to cause: cares, bullseye, four-letter, ninety-seven, klem, heutzutage, aries, callo,\n",
      "2018-11-25 10:17:22,767 - DEBUG: Nearest to would: arises, j'arrête, elenore, obeyed, komma, pato, waddle, oily,\n",
      "2018-11-25 10:17:22,767 - DEBUG: Nearest to would: arises, j'arrête, elenore, obeyed, komma, pato, waddle, oily,\n",
      "2018-11-25 10:17:22,772 - DEBUG: Nearest to find: baited, aamun, rå, venait, automatics, sizes, hojas, pendulum,\n",
      "2018-11-25 10:17:22,772 - DEBUG: Nearest to find: baited, aamun, rå, venait, automatics, sizes, hojas, pendulum,\n",
      "2018-11-25 10:17:22,776 - DEBUG: Nearest to around: lili, cha-cha-cha, geek, dimensional, navire, defiance, conversing, pokus,\n",
      "2018-11-25 10:17:22,776 - DEBUG: Nearest to around: lili, cha-cha-cha, geek, dimensional, navire, defiance, conversing, pokus,\n",
      "2018-11-25 10:17:22,781 - DEBUG: Nearest to look: macchine, coupled, cantas, shops, heya, ha-ah, nervousness, vrille,\n",
      "2018-11-25 10:17:22,781 - DEBUG: Nearest to look: macchine, coupled, cantas, shops, heya, ha-ah, nervousness, vrille,\n",
      "2018-11-25 10:17:22,785 - DEBUG: Nearest to know: legger, mem'ry, spegne, rusted, worms, toppen, wamba, crouched,\n",
      "2018-11-25 10:17:22,785 - DEBUG: Nearest to know: legger, mem'ry, spegne, rusted, worms, toppen, wamba, crouched,\n",
      "2018-11-25 10:17:22,789 - DEBUG: Nearest to 2: candle, inches, fermo, fija, laws, backwoods, cannibalistic, roadie,\n",
      "2018-11-25 10:17:22,789 - DEBUG: Nearest to 2: candle, inches, fermo, fija, laws, backwoods, cannibalistic, roadie,\n",
      "2018-11-25 10:17:22,794 - DEBUG: Nearest to que: florida, creí, daffy, spanking, starman, tortura, mannish, capirai,\n",
      "2018-11-25 10:17:22,794 - DEBUG: Nearest to que: florida, creí, daffy, spanking, starman, tortura, mannish, capirai,\n",
      "2018-11-25 10:17:29,381 - DEBUG: Average loss at step 2000: 117.82897615194321\n",
      "2018-11-25 10:17:29,381 - DEBUG: Average loss at step 2000: 117.82897615194321\n",
      "2018-11-25 10:17:29,384 - DEBUG: Time Elapsed: 0.11390538613001505 minutes\n",
      "2018-11-25 10:17:29,384 - DEBUG: Time Elapsed: 0.11390538613001505 minutes\n",
      "2018-11-25 10:17:35,990 - DEBUG: Average loss at step 4000: 54.7645436053276\n",
      "2018-11-25 10:17:35,990 - DEBUG: Average loss at step 4000: 54.7645436053276\n",
      "2018-11-25 10:17:35,993 - DEBUG: Time Elapsed: 0.2240588625272115 minutes\n",
      "2018-11-25 10:17:35,993 - DEBUG: Time Elapsed: 0.2240588625272115 minutes\n",
      "2018-11-25 10:17:42,565 - DEBUG: Average loss at step 6000: 34.95368115377426\n",
      "2018-11-25 10:17:42,565 - DEBUG: Average loss at step 6000: 34.95368115377426\n",
      "2018-11-25 10:17:42,568 - DEBUG: Time Elapsed: 0.33363446791966755 minutes\n",
      "2018-11-25 10:17:42,568 - DEBUG: Time Elapsed: 0.33363446791966755 minutes\n",
      "2018-11-25 10:17:49,183 - DEBUG: Average loss at step 8000: 24.628021596074106\n",
      "2018-11-25 10:17:49,183 - DEBUG: Average loss at step 8000: 24.628021596074106\n",
      "2018-11-25 10:17:49,186 - DEBUG: Time Elapsed: 0.4439404328664144 minutes\n",
      "2018-11-25 10:17:49,186 - DEBUG: Time Elapsed: 0.4439404328664144 minutes\n",
      "2018-11-25 10:17:55,816 - DEBUG: Average loss at step 10000: 18.596349578648805\n",
      "2018-11-25 10:17:55,816 - DEBUG: Average loss at step 10000: 18.596349578648805\n",
      "2018-11-25 10:17:55,819 - DEBUG: Time Elapsed: 0.5544846137364705 minutes\n",
      "2018-11-25 10:17:55,819 - DEBUG: Time Elapsed: 0.5544846137364705 minutes\n",
      "2018-11-25 10:17:55,867 - DEBUG: Nearest to 1: whoomp, hine, ovo, jee, dann, macho, commande, bim,\n",
      "2018-11-25 10:17:55,867 - DEBUG: Nearest to 1: whoomp, hine, ovo, jee, dann, macho, commande, bim,\n",
      "2018-11-25 10:17:55,876 - DEBUG: Nearest to well: jee, ry, whoomp, peng, berserk, oho, exalted, mm,\n",
      "2018-11-25 10:17:55,876 - DEBUG: Nearest to well: jee, ry, whoomp, peng, berserk, oho, exalted, mm,\n",
      "2018-11-25 10:17:55,887 - DEBUG: Nearest to heart: n't, chaka, bim, peng, mm, oho, ry, taivaan,\n",
      "2018-11-25 10:17:55,887 - DEBUG: Nearest to heart: n't, chaka, bim, peng, mm, oho, ry, taivaan,\n",
      "2018-11-25 10:17:55,894 - DEBUG: Nearest to life: esfrega, macho, mhm, boll, oho, terminal, whoomp, loveee,\n",
      "2018-11-25 10:17:55,894 - DEBUG: Nearest to life: esfrega, macho, mhm, boll, oho, terminal, whoomp, loveee,\n",
      "2018-11-25 10:17:55,900 - DEBUG: Nearest to 're: gabba, exalted, 's, macho, terminal, oho, whoomp, 'm,\n",
      "2018-11-25 10:17:55,900 - DEBUG: Nearest to 're: gabba, exalted, 's, macho, terminal, oho, whoomp, 'm,\n",
      "2018-11-25 10:17:55,905 - DEBUG: Nearest to la: terminal, oho, mm, macho, UNK, whoomp, w-w-w-w-w-w-w-work, bim,\n",
      "2018-11-25 10:17:55,905 - DEBUG: Nearest to la: terminal, oho, mm, macho, UNK, whoomp, w-w-w-w-w-w-w-work, bim,\n",
      "2018-11-25 10:17:55,911 - DEBUG: Nearest to wan: whoomp, ovo, commande, ry, oho, terminal, boll, exalted,\n",
      "2018-11-25 10:17:55,911 - DEBUG: Nearest to wan: whoomp, ovo, commande, ry, oho, terminal, boll, exalted,\n",
      "2018-11-25 10:17:55,916 - DEBUG: Nearest to en: UNK, exalted, esfrega, w-w-w-w-w-w-w-work, terminal, voulez-vous, hat, sobredosis,\n",
      "2018-11-25 10:17:55,916 - DEBUG: Nearest to en: UNK, exalted, esfrega, w-w-w-w-w-w-w-work, terminal, voulez-vous, hat, sobredosis,\n",
      "2018-11-25 10:17:55,921 - DEBUG: Nearest to cause: macho, oho, boll, cares, submit, chaka, whoomp, gabba,\n",
      "2018-11-25 10:17:55,921 - DEBUG: Nearest to cause: macho, oho, boll, cares, submit, chaka, whoomp, gabba,\n",
      "2018-11-25 10:17:55,925 - DEBUG: Nearest to would: gabba, jee, oho, scooby, bim, whoomp, macho, faltó,\n",
      "2018-11-25 10:17:55,925 - DEBUG: Nearest to would: gabba, jee, oho, scooby, bim, whoomp, macho, faltó,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:17:55,930 - DEBUG: Nearest to find: ry, 's, commande, terminal, whoomp, peng, lalalalalalala, ovo,\n",
      "2018-11-25 10:17:55,930 - DEBUG: Nearest to find: ry, 's, commande, terminal, whoomp, peng, lalalalalalala, ovo,\n",
      "2018-11-25 10:17:55,934 - DEBUG: Nearest to around: oho, lili, whoomp, jee, commande, hine, lalalalalalala, taivaan,\n",
      "2018-11-25 10:17:55,934 - DEBUG: Nearest to around: oho, lili, whoomp, jee, commande, hine, lalalalalalala, taivaan,\n",
      "2018-11-25 10:17:55,938 - DEBUG: Nearest to look: oho, mm, macho, exalted, sims, decipher, terminal, bucket,\n",
      "2018-11-25 10:17:55,938 - DEBUG: Nearest to look: oho, mm, macho, exalted, sims, decipher, terminal, bucket,\n",
      "2018-11-25 10:17:55,943 - DEBUG: Nearest to know: macho, exalted, terminal, whoomp, lalalalalalala, oho, peng, bim,\n",
      "2018-11-25 10:17:55,943 - DEBUG: Nearest to know: macho, exalted, terminal, whoomp, lalalalalalala, oho, peng, bim,\n",
      "2018-11-25 10:17:55,947 - DEBUG: Nearest to 2: jee, bim, whoomp, candle, ovo, tic, terminal, oho,\n",
      "2018-11-25 10:17:55,947 - DEBUG: Nearest to 2: jee, bim, whoomp, candle, ovo, tic, terminal, oho,\n",
      "2018-11-25 10:17:55,951 - DEBUG: Nearest to que: UNK, macho, chaka, exalted, oho, whoomp, terminal, w-w-w-w-w-w-w-work,\n",
      "2018-11-25 10:17:55,951 - DEBUG: Nearest to que: UNK, macho, chaka, exalted, oho, whoomp, terminal, w-w-w-w-w-w-w-work,\n",
      "2018-11-25 10:18:02,525 - DEBUG: Average loss at step 12000: 15.307309240698814\n",
      "2018-11-25 10:18:02,525 - DEBUG: Average loss at step 12000: 15.307309240698814\n",
      "2018-11-25 10:18:02,529 - DEBUG: Time Elapsed: 0.6663174589474996 minutes\n",
      "2018-11-25 10:18:02,529 - DEBUG: Time Elapsed: 0.6663174589474996 minutes\n",
      "2018-11-25 10:18:09,119 - DEBUG: Average loss at step 14000: 12.606024904251099\n",
      "2018-11-25 10:18:09,119 - DEBUG: Average loss at step 14000: 12.606024904251099\n",
      "2018-11-25 10:18:09,121 - DEBUG: Time Elapsed: 0.7761953075726827 minutes\n",
      "2018-11-25 10:18:09,121 - DEBUG: Time Elapsed: 0.7761953075726827 minutes\n",
      "2018-11-25 10:18:15,708 - DEBUG: Average loss at step 16000: 10.717744145512581\n",
      "2018-11-25 10:18:15,708 - DEBUG: Average loss at step 16000: 10.717744145512581\n",
      "2018-11-25 10:18:15,711 - DEBUG: Time Elapsed: 0.8860171437263489 minutes\n",
      "2018-11-25 10:18:15,711 - DEBUG: Time Elapsed: 0.8860171437263489 minutes\n",
      "2018-11-25 10:18:22,208 - DEBUG: Average loss at step 18000: 9.835271213650703\n",
      "2018-11-25 10:18:22,208 - DEBUG: Average loss at step 18000: 9.835271213650703\n",
      "2018-11-25 10:18:22,210 - DEBUG: Time Elapsed: 0.9943350513776144 minutes\n",
      "2018-11-25 10:18:22,210 - DEBUG: Time Elapsed: 0.9943350513776144 minutes\n",
      "2018-11-25 10:18:28,767 - DEBUG: Average loss at step 20000: 9.099823249340057\n",
      "2018-11-25 10:18:28,767 - DEBUG: Average loss at step 20000: 9.099823249340057\n",
      "2018-11-25 10:18:28,770 - DEBUG: Time Elapsed: 1.1036713560422262 minutes\n",
      "2018-11-25 10:18:28,770 - DEBUG: Time Elapsed: 1.1036713560422262 minutes\n",
      "2018-11-25 10:18:28,823 - DEBUG: Nearest to 1: hine, whoomp, ovo, ching-a-ling, gamblin, jee, chiquitita, pao,\n",
      "2018-11-25 10:18:28,823 - DEBUG: Nearest to 1: hine, whoomp, ovo, ching-a-ling, gamblin, jee, chiquitita, pao,\n",
      "2018-11-25 10:18:28,835 - DEBUG: Nearest to well: pao, moneymaker, whoomp, ry, oh, ah-ah-ah-ah-ah-ah-ah, love, ching-a-ling,\n",
      "2018-11-25 10:18:28,835 - DEBUG: Nearest to well: pao, moneymaker, whoomp, ry, oh, ah-ah-ah-ah-ah-ah-ah, love, ching-a-ling,\n",
      "2018-11-25 10:18:28,844 - DEBUG: Nearest to heart: chiqui, hooligans, chaka, bim, mm, peng, oho, 's,\n",
      "2018-11-25 10:18:28,844 - DEBUG: Nearest to heart: chiqui, hooligans, chaka, bim, mm, peng, oho, 's,\n",
      "2018-11-25 10:18:28,851 - DEBUG: Nearest to life: 's, macho, esfrega, 'll, chiquitita, boll, pao, chiqui,\n",
      "2018-11-25 10:18:28,851 - DEBUG: Nearest to life: 's, macho, esfrega, 'll, chiquitita, boll, pao, chiqui,\n",
      "2018-11-25 10:18:28,858 - DEBUG: Nearest to 're: 'm, 's, macho, aum, love, hooligans, chiqui, pao,\n",
      "2018-11-25 10:18:28,858 - DEBUG: Nearest to 're: 'm, 's, macho, aum, love, hooligans, chiqui, pao,\n",
      "2018-11-25 10:18:28,863 - DEBUG: Nearest to la: UNK, funkadelala, terminal, aum, oho, chiquitita, ching-a-ling, chiqui,\n",
      "2018-11-25 10:18:28,863 - DEBUG: Nearest to la: UNK, funkadelala, terminal, aum, oho, chiquitita, ching-a-ling, chiqui,\n",
      "2018-11-25 10:18:28,869 - DEBUG: Nearest to wan: whoomp, moneymaker, ah-ah-ah-ah-ah-ah-ah, ovo, chiqui, hooligans, oho, commande,\n",
      "2018-11-25 10:18:28,869 - DEBUG: Nearest to wan: whoomp, moneymaker, ah-ah-ah-ah-ah-ah-ah, ovo, chiqui, hooligans, oho, commande,\n",
      "2018-11-25 10:18:28,874 - DEBUG: Nearest to en: la, exalted, chiquitita, funkadelala, w-w-w-w-w-w-w-work, aum, hooligans, ching-a-ling,\n",
      "2018-11-25 10:18:28,874 - DEBUG: Nearest to en: la, exalted, chiquitita, funkadelala, w-w-w-w-w-w-w-work, aum, hooligans, ching-a-ling,\n",
      "2018-11-25 10:18:28,879 - DEBUG: Nearest to cause: pao, macho, bi-itch, oooo-oooo, funkadelala, oho, boll, chiqui,\n",
      "2018-11-25 10:18:28,879 - DEBUG: Nearest to cause: pao, macho, bi-itch, oooo-oooo, funkadelala, oho, boll, chiqui,\n",
      "2018-11-25 10:18:28,884 - DEBUG: Nearest to would: jee, gabba, oho, pao, docteur, scooby, whoomp, bim,\n",
      "2018-11-25 10:18:28,884 - DEBUG: Nearest to would: jee, gabba, oho, pao, docteur, scooby, whoomp, bim,\n",
      "2018-11-25 10:18:28,888 - DEBUG: Nearest to find: 'm, 's, moneymaker, oooo-oooo, ry, love, n't, commande,\n",
      "2018-11-25 10:18:28,888 - DEBUG: Nearest to find: 'm, 's, moneymaker, oooo-oooo, ry, love, n't, commande,\n",
      "2018-11-25 10:18:28,893 - DEBUG: Nearest to around: 's, aum, visual, pao, oho, funkadelala, whoomp, jee,\n",
      "2018-11-25 10:18:28,893 - DEBUG: Nearest to around: 's, aum, visual, pao, oho, funkadelala, whoomp, jee,\n",
      "2018-11-25 10:18:28,897 - DEBUG: Nearest to look: oho, aum, pao, chiqui, oooo-oooo, gamblin, macho, mm,\n",
      "2018-11-25 10:18:28,897 - DEBUG: Nearest to look: oho, aum, pao, chiqui, oooo-oooo, gamblin, macho, mm,\n",
      "2018-11-25 10:18:28,902 - DEBUG: Nearest to know: 's, n't, macho, pao, 'm, love, hooligans, aum,\n",
      "2018-11-25 10:18:28,902 - DEBUG: Nearest to know: 's, n't, macho, pao, 'm, love, hooligans, aum,\n",
      "2018-11-25 10:18:28,907 - DEBUG: Nearest to 2: ghoul, jee, loyola, ching-a-ling, bim, whoomp, aum, funkadelala,\n",
      "2018-11-25 10:18:28,907 - DEBUG: Nearest to 2: ghoul, jee, loyola, ching-a-ling, bim, whoomp, aum, funkadelala,\n",
      "2018-11-25 10:18:28,911 - DEBUG: Nearest to que: la, UNK, macho, oho, exalted, chaka, hooligans, funkadelala,\n",
      "2018-11-25 10:18:28,911 - DEBUG: Nearest to que: la, UNK, macho, oho, exalted, chaka, hooligans, funkadelala,\n",
      "2018-11-25 10:18:35,503 - DEBUG: Average loss at step 22000: 8.12449878001213\n",
      "2018-11-25 10:18:35,503 - DEBUG: Average loss at step 22000: 8.12449878001213\n",
      "2018-11-25 10:18:35,505 - DEBUG: Time Elapsed: 1.2159313758214314 minutes\n",
      "2018-11-25 10:18:35,505 - DEBUG: Time Elapsed: 1.2159313758214314 minutes\n",
      "2018-11-25 10:18:42,125 - DEBUG: Average loss at step 24000: 7.596151654720306\n",
      "2018-11-25 10:18:42,125 - DEBUG: Average loss at step 24000: 7.596151654720306\n",
      "2018-11-25 10:18:42,128 - DEBUG: Time Elapsed: 1.3262992739677428 minutes\n",
      "2018-11-25 10:18:42,128 - DEBUG: Time Elapsed: 1.3262992739677428 minutes\n",
      "2018-11-25 10:18:48,687 - DEBUG: Average loss at step 26000: 7.24235341155529\n",
      "2018-11-25 10:18:48,687 - DEBUG: Average loss at step 26000: 7.24235341155529\n",
      "2018-11-25 10:18:48,690 - DEBUG: Time Elapsed: 1.4356746474901836 minutes\n",
      "2018-11-25 10:18:48,690 - DEBUG: Time Elapsed: 1.4356746474901836 minutes\n",
      "2018-11-25 10:18:55,307 - DEBUG: Average loss at step 28000: 6.791778000831604\n",
      "2018-11-25 10:18:55,307 - DEBUG: Average loss at step 28000: 6.791778000831604\n",
      "2018-11-25 10:18:55,310 - DEBUG: Time Elapsed: 1.545999292532603 minutes\n",
      "2018-11-25 10:18:55,310 - DEBUG: Time Elapsed: 1.545999292532603 minutes\n",
      "2018-11-25 10:19:01,829 - DEBUG: Average loss at step 30000: 6.828708396434784\n",
      "2018-11-25 10:19:01,829 - DEBUG: Average loss at step 30000: 6.828708396434784\n",
      "2018-11-25 10:19:01,832 - DEBUG: Time Elapsed: 1.654711083571116 minutes\n",
      "2018-11-25 10:19:01,832 - DEBUG: Time Elapsed: 1.654711083571116 minutes\n",
      "2018-11-25 10:19:01,884 - DEBUG: Nearest to 1: inda, do-be-da, cumin, whoomp, jee, hine, ching-a-ling, ovo,\n",
      "2018-11-25 10:19:01,884 - DEBUG: Nearest to 1: inda, do-be-da, cumin, whoomp, jee, hine, ching-a-ling, ovo,\n",
      "2018-11-25 10:19:01,894 - DEBUG: Nearest to well: inda, whoomp, pao, ching-a-ling, moneymaker, ah-ah-ah-ah-ah-ah-ah, ry, peng,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:19:01,894 - DEBUG: Nearest to well: inda, whoomp, pao, ching-a-ling, moneymaker, ah-ah-ah-ah-ah-ah-ah, ry, peng,\n",
      "2018-11-25 10:19:01,903 - DEBUG: Nearest to heart: inda, love, know, animator, chiqui, hooligans, do-be-da, bim,\n",
      "2018-11-25 10:19:01,903 - DEBUG: Nearest to heart: inda, love, know, animator, chiqui, hooligans, do-be-da, bim,\n",
      "2018-11-25 10:19:01,910 - DEBUG: Nearest to life: 's, do-be-da, know, macho, 'll, inda, cumin, like,\n",
      "2018-11-25 10:19:01,910 - DEBUG: Nearest to life: 's, do-be-da, know, macho, 'll, inda, cumin, like,\n",
      "2018-11-25 10:19:01,916 - DEBUG: Nearest to 're: 'm, 's, know, inda, hooligans, pao, aum, do-be-da,\n",
      "2018-11-25 10:19:01,916 - DEBUG: Nearest to 're: 'm, 's, know, inda, hooligans, pao, aum, do-be-da,\n",
      "2018-11-25 10:19:01,922 - DEBUG: Nearest to la: terminal, funkadelala, UNK, inda, chiquitita, aum, oho, pao,\n",
      "2018-11-25 10:19:01,922 - DEBUG: Nearest to la: terminal, funkadelala, UNK, inda, chiquitita, aum, oho, pao,\n",
      "2018-11-25 10:19:01,927 - DEBUG: Nearest to wan: na, inda, whoomp, know, moneymaker, chiqui, hooligans, ah-ah-ah-ah-ah-ah-ah,\n",
      "2018-11-25 10:19:01,927 - DEBUG: Nearest to wan: na, inda, whoomp, know, moneymaker, chiqui, hooligans, ah-ah-ah-ah-ah-ah-ah,\n",
      "2018-11-25 10:19:01,932 - DEBUG: Nearest to en: de, que, la, chiquitita, inda, UNK, funkadelala, exalted,\n",
      "2018-11-25 10:19:01,932 - DEBUG: Nearest to en: de, que, la, chiquitita, inda, UNK, funkadelala, exalted,\n",
      "2018-11-25 10:19:01,937 - DEBUG: Nearest to cause: know, 's, macho, pao, inda, 'm, n't, oooo-oooo,\n",
      "2018-11-25 10:19:01,937 - DEBUG: Nearest to cause: know, 's, macho, pao, inda, 'm, n't, oooo-oooo,\n",
      "2018-11-25 10:19:01,941 - DEBUG: Nearest to would: oho, jee, gabba, eat'em, pao, scooby, love, bim,\n",
      "2018-11-25 10:19:01,941 - DEBUG: Nearest to would: oho, jee, gabba, eat'em, pao, scooby, love, bim,\n",
      "2018-11-25 10:19:01,946 - DEBUG: Nearest to find: 's, 'm, oooo-oooo, moneymaker, 'll, cumin, inda, animator,\n",
      "2018-11-25 10:19:01,946 - DEBUG: Nearest to find: 's, 'm, oooo-oooo, moneymaker, 'll, cumin, inda, animator,\n",
      "2018-11-25 10:19:01,950 - DEBUG: Nearest to around: aum, pao, visual, oho, do-be-da, funkadelala, cumin, whoomp,\n",
      "2018-11-25 10:19:01,950 - DEBUG: Nearest to around: aum, pao, visual, oho, do-be-da, funkadelala, cumin, whoomp,\n",
      "2018-11-25 10:19:01,955 - DEBUG: Nearest to look: oho, aum, do-be-da, 're, pao, chiqui, 's, gamblin,\n",
      "2018-11-25 10:19:01,955 - DEBUG: Nearest to look: oho, aum, do-be-da, 're, pao, chiqui, 's, gamblin,\n",
      "2018-11-25 10:19:01,959 - DEBUG: Nearest to know: 's, do-be-da, whoomp, n't, inda, macho, pao, hooligans,\n",
      "2018-11-25 10:19:01,959 - DEBUG: Nearest to know: 's, do-be-da, whoomp, n't, inda, macho, pao, hooligans,\n",
      "2018-11-25 10:19:01,964 - DEBUG: Nearest to 2: ghoul, ching-a-ling, jee, loyola, know, bim, bomp, 's,\n",
      "2018-11-25 10:19:01,964 - DEBUG: Nearest to 2: ghoul, ching-a-ling, jee, loyola, know, bim, bomp, 's,\n",
      "2018-11-25 10:19:01,969 - DEBUG: Nearest to que: la, de, macho, UNK, oho, aum, terminal, funkadelala,\n",
      "2018-11-25 10:19:01,969 - DEBUG: Nearest to que: la, de, macho, UNK, oho, aum, terminal, funkadelala,\n",
      "2018-11-25 10:19:08,534 - DEBUG: Average loss at step 32000: 6.466293185830116\n",
      "2018-11-25 10:19:08,534 - DEBUG: Average loss at step 32000: 6.466293185830116\n",
      "2018-11-25 10:19:08,537 - DEBUG: Time Elapsed: 1.7664605100949606 minutes\n",
      "2018-11-25 10:19:08,537 - DEBUG: Time Elapsed: 1.7664605100949606 minutes\n",
      "2018-11-25 10:19:15,154 - DEBUG: Average loss at step 34000: 6.369529195070267\n",
      "2018-11-25 10:19:15,154 - DEBUG: Average loss at step 34000: 6.369529195070267\n",
      "2018-11-25 10:19:15,155 - DEBUG: Time Elapsed: 1.8767629822095235 minutes\n",
      "2018-11-25 10:19:15,155 - DEBUG: Time Elapsed: 1.8767629822095235 minutes\n",
      "2018-11-25 10:19:21,675 - DEBUG: Average loss at step 36000: 6.28337421989441\n",
      "2018-11-25 10:19:21,675 - DEBUG: Average loss at step 36000: 6.28337421989441\n",
      "2018-11-25 10:19:21,679 - DEBUG: Time Elapsed: 1.985485521952311 minutes\n",
      "2018-11-25 10:19:21,679 - DEBUG: Time Elapsed: 1.985485521952311 minutes\n",
      "2018-11-25 10:19:28,264 - DEBUG: Average loss at step 38000: 6.07170659995079\n",
      "2018-11-25 10:19:28,264 - DEBUG: Average loss at step 38000: 6.07170659995079\n",
      "2018-11-25 10:19:28,267 - DEBUG: Time Elapsed: 2.095292627811432 minutes\n",
      "2018-11-25 10:19:28,267 - DEBUG: Time Elapsed: 2.095292627811432 minutes\n",
      "2018-11-25 10:19:34,857 - DEBUG: Average loss at step 40000: 6.060306048244238\n",
      "2018-11-25 10:19:34,857 - DEBUG: Average loss at step 40000: 6.060306048244238\n",
      "2018-11-25 10:19:34,860 - DEBUG: Time Elapsed: 2.2051788131395975 minutes\n",
      "2018-11-25 10:19:34,860 - DEBUG: Time Elapsed: 2.2051788131395975 minutes\n",
      "2018-11-25 10:19:34,909 - DEBUG: Nearest to 1: inda, know, do-be-da, cumin, whoomp, saboreando, ching-a-ling, 's,\n",
      "2018-11-25 10:19:34,909 - DEBUG: Nearest to 1: inda, know, do-be-da, cumin, whoomp, saboreando, ching-a-ling, 's,\n",
      "2018-11-25 10:19:34,919 - DEBUG: Nearest to well: know, inda, saboreando, whoomp, pao, oh, ching-a-ling, moneymaker,\n",
      "2018-11-25 10:19:34,919 - DEBUG: Nearest to well: know, inda, saboreando, whoomp, pao, oh, ching-a-ling, moneymaker,\n",
      "2018-11-25 10:19:34,927 - DEBUG: Nearest to heart: inda, hooligans, love, chiqui, animator, do-be-da, barb, know,\n",
      "2018-11-25 10:19:34,927 - DEBUG: Nearest to heart: inda, hooligans, love, chiqui, animator, do-be-da, barb, know,\n",
      "2018-11-25 10:19:34,934 - DEBUG: Nearest to life: 's, know, do-be-da, inda, pao, 'll, hooligans, macho,\n",
      "2018-11-25 10:19:34,934 - DEBUG: Nearest to life: 's, know, do-be-da, inda, pao, 'll, hooligans, macho,\n",
      "2018-11-25 10:19:34,940 - DEBUG: Nearest to 're: 'm, 's, know, inda, hooligans, whoomp, aum, pao,\n",
      "2018-11-25 10:19:34,940 - DEBUG: Nearest to 're: 'm, 's, know, inda, hooligans, whoomp, aum, pao,\n",
      "2018-11-25 10:19:34,945 - DEBUG: Nearest to la: saboreando, funkadelala, oho, inda, terminal, chiquitita, aum, whoomp,\n",
      "2018-11-25 10:19:34,945 - DEBUG: Nearest to la: saboreando, funkadelala, oho, inda, terminal, chiquitita, aum, whoomp,\n",
      "2018-11-25 10:19:34,950 - DEBUG: Nearest to wan: inda, know, whoomp, hooligans, moneymaker, na, do-be-da, pao,\n",
      "2018-11-25 10:19:34,950 - DEBUG: Nearest to wan: inda, know, whoomp, hooligans, moneymaker, na, do-be-da, pao,\n",
      "2018-11-25 10:19:34,955 - DEBUG: Nearest to en: de, la, inda, chiquitita, funkadelala, aum, que, ching-a-ling,\n",
      "2018-11-25 10:19:34,955 - DEBUG: Nearest to en: de, la, inda, chiquitita, funkadelala, aum, que, ching-a-ling,\n",
      "2018-11-25 10:19:34,960 - DEBUG: Nearest to cause: zimbo, know, 'm, pao, 's, inda, macho, n't,\n",
      "2018-11-25 10:19:34,960 - DEBUG: Nearest to cause: zimbo, know, 'm, pao, 's, inda, macho, n't,\n",
      "2018-11-25 10:19:34,965 - DEBUG: Nearest to would: oho, eat'em, pao, jee, inda, gabba, whoomp, saboreando,\n",
      "2018-11-25 10:19:34,965 - DEBUG: Nearest to would: oho, eat'em, pao, jee, inda, gabba, whoomp, saboreando,\n",
      "2018-11-25 10:19:34,969 - DEBUG: Nearest to find: 'll, oooo-oooo, love, moneymaker, inda, 's, cumin, animator,\n",
      "2018-11-25 10:19:34,969 - DEBUG: Nearest to find: 'll, oooo-oooo, love, moneymaker, inda, 's, cumin, animator,\n",
      "2018-11-25 10:19:34,974 - DEBUG: Nearest to around: 're, aum, saboreando, pao, oho, do-be-da, cumin, ching-a-ling,\n",
      "2018-11-25 10:19:34,974 - DEBUG: Nearest to around: 're, aum, saboreando, pao, oho, do-be-da, cumin, ching-a-ling,\n",
      "2018-11-25 10:19:34,978 - DEBUG: Nearest to look: oho, do-be-da, aum, chiqui, pao, saboreando, zimbo, macho,\n",
      "2018-11-25 10:19:34,978 - DEBUG: Nearest to look: oho, do-be-da, aum, chiqui, pao, saboreando, zimbo, macho,\n",
      "2018-11-25 10:19:34,983 - DEBUG: Nearest to know: 's, whoomp, pao, inda, macho, do-be-da, n't, saboreando,\n",
      "2018-11-25 10:19:34,983 - DEBUG: Nearest to know: 's, whoomp, pao, inda, macho, do-be-da, n't, saboreando,\n",
      "2018-11-25 10:19:34,987 - DEBUG: Nearest to 2: ghoul, rainman, ching-a-ling, jee, loyola, 's, zimbo, bim,\n",
      "2018-11-25 10:19:34,987 - DEBUG: Nearest to 2: ghoul, rainman, ching-a-ling, jee, loyola, 's, zimbo, bim,\n",
      "2018-11-25 10:19:34,992 - DEBUG: Nearest to que: de, la, macho, oho, saboreando, aum, pao, tini,\n",
      "2018-11-25 10:19:34,992 - DEBUG: Nearest to que: de, la, macho, oho, saboreando, aum, pao, tini,\n",
      "2018-11-25 10:19:41,518 - DEBUG: Average loss at step 42000: 5.9565499958992\n",
      "2018-11-25 10:19:41,518 - DEBUG: Average loss at step 42000: 5.9565499958992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:19:41,521 - DEBUG: Time Elapsed: 2.3161828597386678 minutes\n",
      "2018-11-25 10:19:41,521 - DEBUG: Time Elapsed: 2.3161828597386678 minutes\n",
      "2018-11-25 10:19:48,144 - DEBUG: Average loss at step 44000: 5.741657909452915\n",
      "2018-11-25 10:19:48,144 - DEBUG: Average loss at step 44000: 5.741657909452915\n",
      "2018-11-25 10:19:48,147 - DEBUG: Time Elapsed: 2.42662593126297 minutes\n",
      "2018-11-25 10:19:48,147 - DEBUG: Time Elapsed: 2.42662593126297 minutes\n",
      "2018-11-25 10:19:54,685 - DEBUG: Average loss at step 46000: 5.7037414273321625\n",
      "2018-11-25 10:19:54,685 - DEBUG: Average loss at step 46000: 5.7037414273321625\n",
      "2018-11-25 10:19:54,688 - DEBUG: Time Elapsed: 2.535642659664154 minutes\n",
      "2018-11-25 10:19:54,688 - DEBUG: Time Elapsed: 2.535642659664154 minutes\n",
      "2018-11-25 10:20:01,235 - DEBUG: Average loss at step 48000: 5.657136115074158\n",
      "2018-11-25 10:20:01,235 - DEBUG: Average loss at step 48000: 5.657136115074158\n",
      "2018-11-25 10:20:01,238 - DEBUG: Time Elapsed: 2.644806778430939 minutes\n",
      "2018-11-25 10:20:01,238 - DEBUG: Time Elapsed: 2.644806778430939 minutes\n",
      "2018-11-25 10:20:07,826 - DEBUG: Average loss at step 50000: 5.547277450978756\n",
      "2018-11-25 10:20:07,826 - DEBUG: Average loss at step 50000: 5.547277450978756\n",
      "2018-11-25 10:20:07,829 - DEBUG: Time Elapsed: 2.7546608328819273 minutes\n",
      "2018-11-25 10:20:07,829 - DEBUG: Time Elapsed: 2.7546608328819273 minutes\n",
      "2018-11-25 10:20:07,880 - DEBUG: Nearest to 1: inda, do-be-da, whoomp, 's, ching-a-ling, cumin, jee, saboreando,\n",
      "2018-11-25 10:20:07,880 - DEBUG: Nearest to 1: inda, do-be-da, whoomp, 's, ching-a-ling, cumin, jee, saboreando,\n",
      "2018-11-25 10:20:07,892 - DEBUG: Nearest to well: know, inda, saboreando, whoomp, pao, ching-a-ling, ry, oh,\n",
      "2018-11-25 10:20:07,892 - DEBUG: Nearest to well: know, inda, saboreando, whoomp, pao, ching-a-ling, ry, oh,\n",
      "2018-11-25 10:20:07,901 - DEBUG: Nearest to heart: love, inda, hooligans, do-be-da, animator, bestiola, chiqui, barb,\n",
      "2018-11-25 10:20:07,901 - DEBUG: Nearest to heart: love, inda, hooligans, do-be-da, animator, bestiola, chiqui, barb,\n",
      "2018-11-25 10:20:07,908 - DEBUG: Nearest to life: 's, time, do-be-da, pao, inda, hooligans, saboreando, chiqui,\n",
      "2018-11-25 10:20:07,908 - DEBUG: Nearest to life: 's, time, do-be-da, pao, inda, hooligans, saboreando, chiqui,\n",
      "2018-11-25 10:20:07,914 - DEBUG: Nearest to 're: 'm, 's, know, inda, pao, aum, do-be-da, hooligans,\n",
      "2018-11-25 10:20:07,914 - DEBUG: Nearest to 're: 'm, 's, know, inda, pao, aum, do-be-da, hooligans,\n",
      "2018-11-25 10:20:07,920 - DEBUG: Nearest to la: de, saboreando, terminal, funkadelala, UNK, aum, inda, whoomp,\n",
      "2018-11-25 10:20:07,920 - DEBUG: Nearest to la: de, saboreando, terminal, funkadelala, UNK, aum, inda, whoomp,\n",
      "2018-11-25 10:20:07,925 - DEBUG: Nearest to wan: na, know, gon, inda, whoomp, hooligans, do-be-da, pao,\n",
      "2018-11-25 10:20:07,925 - DEBUG: Nearest to wan: na, know, gon, inda, whoomp, hooligans, do-be-da, pao,\n",
      "2018-11-25 10:20:07,937 - DEBUG: Nearest to en: de, la, aum, chiquitita, inda, UNK, funkadelala, ching-a-ling,\n",
      "2018-11-25 10:20:07,937 - DEBUG: Nearest to en: de, la, aum, chiquitita, inda, UNK, funkadelala, ching-a-ling,\n",
      "2018-11-25 10:20:07,946 - DEBUG: Nearest to cause: zimbo, 's, n't, know, inda, pao, macho, chiqui,\n",
      "2018-11-25 10:20:07,946 - DEBUG: Nearest to cause: zimbo, 's, n't, know, inda, pao, macho, chiqui,\n",
      "2018-11-25 10:20:07,953 - DEBUG: Nearest to would: pao, could, eat'em, jee, oho, inda, saboreando, like,\n",
      "2018-11-25 10:20:07,953 - DEBUG: Nearest to would: pao, could, eat'em, jee, oho, inda, saboreando, like,\n",
      "2018-11-25 10:20:07,960 - DEBUG: Nearest to find: love, inda, 's, 'll, oooo-oooo, animator, cumin, moneymaker,\n",
      "2018-11-25 10:20:07,960 - DEBUG: Nearest to find: love, inda, 's, 'll, oooo-oooo, animator, cumin, moneymaker,\n",
      "2018-11-25 10:20:07,965 - DEBUG: Nearest to around: aum, saboreando, chiqui, 're, pao, do-be-da, oho, funkadelala,\n",
      "2018-11-25 10:20:07,965 - DEBUG: Nearest to around: aum, saboreando, chiqui, 're, pao, do-be-da, oho, funkadelala,\n",
      "2018-11-25 10:20:07,971 - DEBUG: Nearest to look: do-be-da, aum, oho, chiqui, see, zimbo, pao, saboreando,\n",
      "2018-11-25 10:20:07,971 - DEBUG: Nearest to look: do-be-da, aum, oho, chiqui, see, zimbo, pao, saboreando,\n",
      "2018-11-25 10:20:07,976 - DEBUG: Nearest to know: 's, pao, whoomp, inda, 're, go, aum, macho,\n",
      "2018-11-25 10:20:07,976 - DEBUG: Nearest to know: 's, pao, whoomp, inda, 're, go, aum, macho,\n",
      "2018-11-25 10:20:07,981 - DEBUG: Nearest to 2: rainman, ghoul, ching-a-ling, 's, jee, loyola, UNK, zimbo,\n",
      "2018-11-25 10:20:07,981 - DEBUG: Nearest to 2: rainman, ghoul, ching-a-ling, 's, jee, loyola, UNK, zimbo,\n",
      "2018-11-25 10:20:07,985 - DEBUG: Nearest to que: de, la, oho, macho, saboreando, aum, pao, rainman,\n",
      "2018-11-25 10:20:07,985 - DEBUG: Nearest to que: de, la, oho, macho, saboreando, aum, pao, rainman,\n",
      "2018-11-25 10:20:14,554 - DEBUG: Average loss at step 52000: 5.56556882840395\n",
      "2018-11-25 10:20:14,554 - DEBUG: Average loss at step 52000: 5.56556882840395\n",
      "2018-11-25 10:20:14,557 - DEBUG: Time Elapsed: 2.8667940855026246 minutes\n",
      "2018-11-25 10:20:14,557 - DEBUG: Time Elapsed: 2.8667940855026246 minutes\n",
      "2018-11-25 10:20:21,060 - DEBUG: Average loss at step 54000: 5.612699871659279\n",
      "2018-11-25 10:20:21,060 - DEBUG: Average loss at step 54000: 5.612699871659279\n",
      "2018-11-25 10:20:21,063 - DEBUG: Time Elapsed: 2.9752167026201883 minutes\n",
      "2018-11-25 10:20:21,063 - DEBUG: Time Elapsed: 2.9752167026201883 minutes\n",
      "2018-11-25 10:20:27,661 - DEBUG: Average loss at step 56000: 5.413390168070793\n",
      "2018-11-25 10:20:27,661 - DEBUG: Average loss at step 56000: 5.413390168070793\n",
      "2018-11-25 10:20:27,664 - DEBUG: Time Elapsed: 3.085238500436147 minutes\n",
      "2018-11-25 10:20:27,664 - DEBUG: Time Elapsed: 3.085238500436147 minutes\n",
      "2018-11-25 10:20:34,235 - DEBUG: Average loss at step 58000: 5.846984134435654\n",
      "2018-11-25 10:20:34,235 - DEBUG: Average loss at step 58000: 5.846984134435654\n",
      "2018-11-25 10:20:34,238 - DEBUG: Time Elapsed: 3.194808522860209 minutes\n",
      "2018-11-25 10:20:34,238 - DEBUG: Time Elapsed: 3.194808522860209 minutes\n",
      "2018-11-25 10:20:40,828 - DEBUG: Average loss at step 60000: 5.422883883446455\n",
      "2018-11-25 10:20:40,828 - DEBUG: Average loss at step 60000: 5.422883883446455\n",
      "2018-11-25 10:20:40,830 - DEBUG: Time Elapsed: 3.304681404431661 minutes\n",
      "2018-11-25 10:20:40,830 - DEBUG: Time Elapsed: 3.304681404431661 minutes\n",
      "2018-11-25 10:20:40,882 - DEBUG: Nearest to 1: 's, inda, whoomp, do-be-da, ching-a-ling, jee, saboreando, cumin,\n",
      "2018-11-25 10:20:40,882 - DEBUG: Nearest to 1: 's, inda, whoomp, do-be-da, ching-a-ling, jee, saboreando, cumin,\n",
      "2018-11-25 10:20:40,891 - DEBUG: Nearest to well: inda, saboreando, know, whoomp, pao, ching-a-ling, hooligans, chiqui,\n",
      "2018-11-25 10:20:40,891 - DEBUG: Nearest to well: inda, saboreando, know, whoomp, pao, ching-a-ling, hooligans, chiqui,\n",
      "2018-11-25 10:20:40,898 - DEBUG: Nearest to heart: love, inda, hooligans, do-be-da, animator, chiqui, 're, bestiola,\n",
      "2018-11-25 10:20:40,898 - DEBUG: Nearest to heart: love, inda, hooligans, do-be-da, animator, chiqui, 're, bestiola,\n",
      "2018-11-25 10:20:40,905 - DEBUG: Nearest to life: time, pao, do-be-da, inda, hooligans, 's, aum, know,\n",
      "2018-11-25 10:20:40,905 - DEBUG: Nearest to life: time, pao, do-be-da, inda, hooligans, 's, aum, know,\n",
      "2018-11-25 10:20:40,911 - DEBUG: Nearest to 're: 'm, 's, inda, know, pao, hooligans, whoomp, do-be-da,\n",
      "2018-11-25 10:20:40,911 - DEBUG: Nearest to 're: 'm, 's, inda, know, pao, hooligans, whoomp, do-be-da,\n",
      "2018-11-25 10:20:40,916 - DEBUG: Nearest to la: de, que, saboreando, funkadelala, chiquitita, inda, aum, rainman,\n",
      "2018-11-25 10:20:40,916 - DEBUG: Nearest to la: de, que, saboreando, funkadelala, chiquitita, inda, aum, rainman,\n",
      "2018-11-25 10:20:40,921 - DEBUG: Nearest to wan: na, gon, whoomp, inda, pao, know, do-be-da, hooligans,\n",
      "2018-11-25 10:20:40,921 - DEBUG: Nearest to wan: na, gon, whoomp, inda, pao, know, do-be-da, hooligans,\n",
      "2018-11-25 10:20:40,926 - DEBUG: Nearest to en: de, la, aum, noelia, inda, funkadelala, chiquitita, ching-a-ling,\n",
      "2018-11-25 10:20:40,926 - DEBUG: Nearest to en: de, la, aum, noelia, inda, funkadelala, chiquitita, ching-a-ling,\n",
      "2018-11-25 10:20:40,930 - DEBUG: Nearest to cause: zimbo, pao, inda, blackman, got, get, macho, 're,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:20:40,930 - DEBUG: Nearest to cause: zimbo, pao, inda, blackman, got, get, macho, 're,\n",
      "2018-11-25 10:20:40,935 - DEBUG: Nearest to would: could, pao, never, eat'em, inda, jee, oho, saboreando,\n",
      "2018-11-25 10:20:40,935 - DEBUG: Nearest to would: could, pao, never, eat'em, inda, jee, oho, saboreando,\n",
      "2018-11-25 10:20:40,939 - DEBUG: Nearest to find: 'll, love, see, inda, oooo-oooo, aum, animator, cumin,\n",
      "2018-11-25 10:20:40,939 - DEBUG: Nearest to find: 'll, love, see, inda, oooo-oooo, aum, animator, cumin,\n",
      "2018-11-25 10:20:40,944 - DEBUG: Nearest to around: aum, 's, saboreando, chiqui, cumin, pao, ching-a-ling, do-be-da,\n",
      "2018-11-25 10:20:40,944 - DEBUG: Nearest to around: aum, 's, saboreando, chiqui, cumin, pao, ching-a-ling, do-be-da,\n",
      "2018-11-25 10:20:40,948 - DEBUG: Nearest to look: do-be-da, aum, oho, see, chiqui, 's, pao, saboreando,\n",
      "2018-11-25 10:20:40,948 - DEBUG: Nearest to look: do-be-da, aum, oho, see, chiqui, 's, pao, saboreando,\n",
      "2018-11-25 10:20:40,953 - DEBUG: Nearest to know: inda, whoomp, pao, aum, 's, saboreando, do-be-da, hooligans,\n",
      "2018-11-25 10:20:40,953 - DEBUG: Nearest to know: inda, whoomp, pao, aum, 's, saboreando, do-be-da, hooligans,\n",
      "2018-11-25 10:20:40,957 - DEBUG: Nearest to 2: ghoul, rainman, ching-a-ling, jee, UNK, loyola, chorus, 're,\n",
      "2018-11-25 10:20:40,957 - DEBUG: Nearest to 2: ghoul, rainman, ching-a-ling, jee, UNK, loyola, chorus, 're,\n",
      "2018-11-25 10:20:40,962 - DEBUG: Nearest to que: de, la, saboreando, aum, macho, rainman, moneymaker, pao,\n",
      "2018-11-25 10:20:40,962 - DEBUG: Nearest to que: de, la, saboreando, aum, macho, rainman, moneymaker, pao,\n",
      "2018-11-25 10:20:47,494 - DEBUG: Average loss at step 62000: 5.480081014484167\n",
      "2018-11-25 10:20:47,494 - DEBUG: Average loss at step 62000: 5.480081014484167\n",
      "2018-11-25 10:20:47,497 - DEBUG: Time Elapsed: 3.4157854398091634 minutes\n",
      "2018-11-25 10:20:47,497 - DEBUG: Time Elapsed: 3.4157854398091634 minutes\n",
      "2018-11-25 10:20:54,110 - DEBUG: Average loss at step 64000: 5.4031850978732106\n",
      "2018-11-25 10:20:54,110 - DEBUG: Average loss at step 64000: 5.4031850978732106\n",
      "2018-11-25 10:20:54,113 - DEBUG: Time Elapsed: 3.526061999797821 minutes\n",
      "2018-11-25 10:20:54,113 - DEBUG: Time Elapsed: 3.526061999797821 minutes\n",
      "2018-11-25 10:21:00,701 - DEBUG: Average loss at step 66000: 5.40018897408247\n",
      "2018-11-25 10:21:00,701 - DEBUG: Average loss at step 66000: 5.40018897408247\n",
      "2018-11-25 10:21:00,704 - DEBUG: Time Elapsed: 3.635901188850403 minutes\n",
      "2018-11-25 10:21:00,704 - DEBUG: Time Elapsed: 3.635901188850403 minutes\n",
      "2018-11-25 10:21:07,256 - DEBUG: Average loss at step 68000: 5.316738546609878\n",
      "2018-11-25 10:21:07,256 - DEBUG: Average loss at step 68000: 5.316738546609878\n",
      "2018-11-25 10:21:07,259 - DEBUG: Time Elapsed: 3.7451531012852985 minutes\n",
      "2018-11-25 10:21:07,259 - DEBUG: Time Elapsed: 3.7451531012852985 minutes\n",
      "2018-11-25 10:21:13,837 - DEBUG: Average loss at step 70000: 5.255528633713722\n",
      "2018-11-25 10:21:13,837 - DEBUG: Average loss at step 70000: 5.255528633713722\n",
      "2018-11-25 10:21:13,840 - DEBUG: Time Elapsed: 3.854846672217051 minutes\n",
      "2018-11-25 10:21:13,840 - DEBUG: Time Elapsed: 3.854846672217051 minutes\n",
      "2018-11-25 10:21:13,887 - DEBUG: Nearest to 1: chorus, corinna, inda, whoomp, libe, doo-ah, saboreando, do-be-da,\n",
      "2018-11-25 10:21:13,887 - DEBUG: Nearest to 1: chorus, corinna, inda, whoomp, libe, doo-ah, saboreando, do-be-da,\n",
      "2018-11-25 10:21:13,892 - DEBUG: Nearest to well: corinna, inda, know, doo-ah, pao, cubs, saboreando, whoomp,\n",
      "2018-11-25 10:21:13,892 - DEBUG: Nearest to well: corinna, inda, know, doo-ah, pao, cubs, saboreando, whoomp,\n",
      "2018-11-25 10:21:13,896 - DEBUG: Nearest to heart: inda, love, hooligans, do-be-da, doo-ah, libe, corinna, 're,\n",
      "2018-11-25 10:21:13,896 - DEBUG: Nearest to heart: inda, love, hooligans, do-be-da, doo-ah, libe, corinna, 're,\n",
      "2018-11-25 10:21:13,900 - DEBUG: Nearest to life: pao, lucinda, inda, hooligans, corinna, do-be-da, aum, know,\n",
      "2018-11-25 10:21:13,900 - DEBUG: Nearest to life: pao, lucinda, inda, hooligans, corinna, do-be-da, aum, know,\n",
      "2018-11-25 10:21:13,904 - DEBUG: Nearest to 're: 'm, 's, know, hooligans, inda, moneymaker, doo-ah, whoomp,\n",
      "2018-11-25 10:21:13,904 - DEBUG: Nearest to 're: 'm, 's, know, hooligans, inda, moneymaker, doo-ah, whoomp,\n",
      "2018-11-25 10:21:13,908 - DEBUG: Nearest to la: de, libe, chiquitita, saboreando, funkadelala, inda, lucinda, rainman,\n",
      "2018-11-25 10:21:13,908 - DEBUG: Nearest to la: de, libe, chiquitita, saboreando, funkadelala, inda, lucinda, rainman,\n",
      "2018-11-25 10:21:13,912 - DEBUG: Nearest to wan: gon, na, know, corinna, pao, go, whoomp, inda,\n",
      "2018-11-25 10:21:13,912 - DEBUG: Nearest to wan: gon, na, know, corinna, pao, go, whoomp, inda,\n",
      "2018-11-25 10:21:13,916 - DEBUG: Nearest to en: de, la, aum, libe, noelia, funkadelala, UNK, inda,\n",
      "2018-11-25 10:21:13,916 - DEBUG: Nearest to en: de, la, aum, libe, noelia, funkadelala, UNK, inda,\n",
      "2018-11-25 10:21:13,920 - DEBUG: Nearest to cause: know, zimbo, pao, inda, doo-ah, 's, do-be-da, iô,\n",
      "2018-11-25 10:21:13,920 - DEBUG: Nearest to cause: know, zimbo, pao, inda, doo-ah, 's, do-be-da, iô,\n",
      "2018-11-25 10:21:13,924 - DEBUG: Nearest to would: could, never, pao, corinna, inda, eat'em, n't, whoomp,\n",
      "2018-11-25 10:21:13,924 - DEBUG: Nearest to would: could, never, pao, corinna, inda, eat'em, n't, whoomp,\n",
      "2018-11-25 10:21:13,928 - DEBUG: Nearest to find: 'll, way, lucinda, see, never, inda, corinna, doo-ah,\n",
      "2018-11-25 10:21:13,928 - DEBUG: Nearest to find: 'll, way, lucinda, see, never, inda, corinna, doo-ah,\n",
      "2018-11-25 10:21:13,932 - DEBUG: Nearest to around: doo-ah, aum, chiqui, lucinda, saboreando, oho, do-be-da, like,\n",
      "2018-11-25 10:21:13,932 - DEBUG: Nearest to around: doo-ah, aum, chiqui, lucinda, saboreando, oho, do-be-da, like,\n",
      "2018-11-25 10:21:13,936 - DEBUG: Nearest to look: see, aum, do-be-da, oho, chiqui, libe, 's, pao,\n",
      "2018-11-25 10:21:13,936 - DEBUG: Nearest to look: see, aum, do-be-da, oho, chiqui, libe, 's, pao,\n",
      "2018-11-25 10:21:13,940 - DEBUG: Nearest to know: pao, inda, whoomp, doo-ah, aum, corinna, lucinda, hooligans,\n",
      "2018-11-25 10:21:13,940 - DEBUG: Nearest to know: pao, inda, whoomp, doo-ah, aum, corinna, lucinda, hooligans,\n",
      "2018-11-25 10:21:13,944 - DEBUG: Nearest to 2: rainman, chorus, ching-a-ling, corinna, ghoul, loyola, tweedlee, 're,\n",
      "2018-11-25 10:21:13,944 - DEBUG: Nearest to 2: rainman, chorus, ching-a-ling, corinna, ghoul, loyola, tweedlee, 're,\n",
      "2018-11-25 10:21:13,948 - DEBUG: Nearest to que: de, aum, saboreando, libe, iô, whoomp, rainman, la,\n",
      "2018-11-25 10:21:13,948 - DEBUG: Nearest to que: de, aum, saboreando, libe, iô, whoomp, rainman, la,\n",
      "2018-11-25 10:21:20,408 - DEBUG: Average loss at step 72000: 5.356342606544494\n",
      "2018-11-25 10:21:20,408 - DEBUG: Average loss at step 72000: 5.356342606544494\n",
      "2018-11-25 10:21:20,411 - DEBUG: Time Elapsed: 3.964358679453532 minutes\n",
      "2018-11-25 10:21:20,411 - DEBUG: Time Elapsed: 3.964358679453532 minutes\n",
      "2018-11-25 10:21:27,018 - DEBUG: Average loss at step 74000: 5.222921408236027\n",
      "2018-11-25 10:21:27,018 - DEBUG: Average loss at step 74000: 5.222921408236027\n",
      "2018-11-25 10:21:27,021 - DEBUG: Time Elapsed: 4.0745314955711365 minutes\n",
      "2018-11-25 10:21:27,021 - DEBUG: Time Elapsed: 4.0745314955711365 minutes\n",
      "2018-11-25 10:21:33,582 - DEBUG: Average loss at step 76000: 5.282659096240997\n",
      "2018-11-25 10:21:33,582 - DEBUG: Average loss at step 76000: 5.282659096240997\n",
      "2018-11-25 10:21:33,585 - DEBUG: Time Elapsed: 4.183923808733622 minutes\n",
      "2018-11-25 10:21:33,585 - DEBUG: Time Elapsed: 4.183923808733622 minutes\n",
      "2018-11-25 10:21:40,194 - DEBUG: Average loss at step 78000: 5.219855593860149\n",
      "2018-11-25 10:21:40,194 - DEBUG: Average loss at step 78000: 5.219855593860149\n",
      "2018-11-25 10:21:40,197 - DEBUG: Time Elapsed: 4.294131664435069 minutes\n",
      "2018-11-25 10:21:40,197 - DEBUG: Time Elapsed: 4.294131664435069 minutes\n",
      "2018-11-25 10:21:46,767 - DEBUG: Average loss at step 80000: 5.196623377710581\n",
      "2018-11-25 10:21:46,767 - DEBUG: Average loss at step 80000: 5.196623377710581\n",
      "2018-11-25 10:21:46,769 - DEBUG: Time Elapsed: 4.403660639127096 minutes\n",
      "2018-11-25 10:21:46,769 - DEBUG: Time Elapsed: 4.403660639127096 minutes\n",
      "2018-11-25 10:21:46,812 - DEBUG: Nearest to 1: chorus, 's, a-ask, corinna, inda, 2, whoomp, doo-ah,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:21:46,812 - DEBUG: Nearest to 1: chorus, 's, a-ask, corinna, inda, 2, whoomp, doo-ah,\n",
      "2018-11-25 10:21:46,822 - DEBUG: Nearest to well: a-ask, corinna, inda, doo-ah, 's, hooligans, pao, whoomp,\n",
      "2018-11-25 10:21:46,822 - DEBUG: Nearest to well: a-ask, corinna, inda, doo-ah, 's, hooligans, pao, whoomp,\n",
      "2018-11-25 10:21:46,829 - DEBUG: Nearest to heart: inda, love, a-ask, hooligans, doo-ah, do-be-da, libe, 're,\n",
      "2018-11-25 10:21:46,829 - DEBUG: Nearest to heart: inda, love, a-ask, hooligans, doo-ah, do-be-da, libe, 're,\n",
      "2018-11-25 10:21:46,836 - DEBUG: Nearest to life: a-ask, inda, lucinda, pao, hooligans, corinna, 's, do-be-da,\n",
      "2018-11-25 10:21:46,836 - DEBUG: Nearest to life: a-ask, inda, lucinda, pao, hooligans, corinna, 's, do-be-da,\n",
      "2018-11-25 10:21:46,841 - DEBUG: Nearest to 're: 'm, know, 's, a-ask, hooligans, inda, moneymaker, doo-ah,\n",
      "2018-11-25 10:21:46,841 - DEBUG: Nearest to 're: 'm, know, 's, a-ask, hooligans, inda, moneymaker, doo-ah,\n",
      "2018-11-25 10:21:46,846 - DEBUG: Nearest to la: que, saboreando, libe, de, aum, whoomp, oho, iô,\n",
      "2018-11-25 10:21:46,846 - DEBUG: Nearest to la: que, saboreando, libe, de, aum, whoomp, oho, iô,\n",
      "2018-11-25 10:21:46,851 - DEBUG: Nearest to wan: gon, na, know, corinna, pao, a-ask, inda, want,\n",
      "2018-11-25 10:21:46,851 - DEBUG: Nearest to wan: gon, na, know, corinna, pao, a-ask, inda, want,\n",
      "2018-11-25 10:21:46,855 - DEBUG: Nearest to en: de, la, UNK, aum, libe, funkadelala, noelia, el,\n",
      "2018-11-25 10:21:46,855 - DEBUG: Nearest to en: de, la, UNK, aum, libe, funkadelala, noelia, el,\n",
      "2018-11-25 10:21:46,865 - DEBUG: Nearest to cause: know, zimbo, a-ask, inda, pao, 'm, do-be-da, macho,\n",
      "2018-11-25 10:21:46,865 - DEBUG: Nearest to cause: know, zimbo, a-ask, inda, pao, 'm, do-be-da, macho,\n",
      "2018-11-25 10:21:46,877 - DEBUG: Nearest to would: could, never, kamarage, 'd, a-ask, pao, corinna, inda,\n",
      "2018-11-25 10:21:46,877 - DEBUG: Nearest to would: could, never, kamarage, 'd, a-ask, pao, corinna, inda,\n",
      "2018-11-25 10:21:46,885 - DEBUG: Nearest to find: way, go, lucinda, a-ask, see, 'll, inda, doo-ah,\n",
      "2018-11-25 10:21:46,885 - DEBUG: Nearest to find: way, go, lucinda, a-ask, see, 'll, inda, doo-ah,\n",
      "2018-11-25 10:21:46,893 - DEBUG: Nearest to around: aum, chiqui, doo-ah, saboreando, oho, do-be-da, lucinda, corinna,\n",
      "2018-11-25 10:21:46,893 - DEBUG: Nearest to around: aum, chiqui, doo-ah, saboreando, oho, do-be-da, lucinda, corinna,\n",
      "2018-11-25 10:21:46,899 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, oho, chiqui, doo-ah, libe,\n",
      "2018-11-25 10:21:46,899 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, oho, chiqui, doo-ah, libe,\n",
      "2018-11-25 10:21:46,905 - DEBUG: Nearest to know: inda, a-ask, love, pao, whoomp, n't, aum, go,\n",
      "2018-11-25 10:21:46,905 - DEBUG: Nearest to know: inda, a-ask, love, pao, whoomp, n't, aum, go,\n",
      "2018-11-25 10:21:46,910 - DEBUG: Nearest to 2: chorus, corinna, rainman, ching-a-ling, 1, ghoul, a-ask, loyola,\n",
      "2018-11-25 10:21:46,910 - DEBUG: Nearest to 2: chorus, corinna, rainman, ching-a-ling, 1, ghoul, a-ask, loyola,\n",
      "2018-11-25 10:21:46,915 - DEBUG: Nearest to que: la, de, libe, saboreando, oho, iô, aum, macho,\n",
      "2018-11-25 10:21:46,915 - DEBUG: Nearest to que: la, de, libe, saboreando, oho, iô, aum, macho,\n",
      "2018-11-25 10:21:53,511 - DEBUG: Average loss at step 82000: 5.263919025897979\n",
      "2018-11-25 10:21:53,511 - DEBUG: Average loss at step 82000: 5.263919025897979\n",
      "2018-11-25 10:21:53,514 - DEBUG: Time Elapsed: 4.5160722732543945 minutes\n",
      "2018-11-25 10:21:53,514 - DEBUG: Time Elapsed: 4.5160722732543945 minutes\n",
      "2018-11-25 10:22:00,085 - DEBUG: Average loss at step 84000: 5.168154133677483\n",
      "2018-11-25 10:22:00,085 - DEBUG: Average loss at step 84000: 5.168154133677483\n",
      "2018-11-25 10:22:00,089 - DEBUG: Time Elapsed: 4.62565305630366 minutes\n",
      "2018-11-25 10:22:00,089 - DEBUG: Time Elapsed: 4.62565305630366 minutes\n",
      "2018-11-25 10:22:06,661 - DEBUG: Average loss at step 86000: 5.209112091183663\n",
      "2018-11-25 10:22:06,661 - DEBUG: Average loss at step 86000: 5.209112091183663\n",
      "2018-11-25 10:22:06,664 - DEBUG: Time Elapsed: 4.735248025258382 minutes\n",
      "2018-11-25 10:22:06,664 - DEBUG: Time Elapsed: 4.735248025258382 minutes\n",
      "2018-11-25 10:22:13,231 - DEBUG: Average loss at step 88000: 5.07913358438015\n",
      "2018-11-25 10:22:13,231 - DEBUG: Average loss at step 88000: 5.07913358438015\n",
      "2018-11-25 10:22:13,233 - DEBUG: Time Elapsed: 4.844721428553263 minutes\n",
      "2018-11-25 10:22:13,233 - DEBUG: Time Elapsed: 4.844721428553263 minutes\n",
      "2018-11-25 10:22:19,847 - DEBUG: Average loss at step 90000: 5.0876162379980086\n",
      "2018-11-25 10:22:19,847 - DEBUG: Average loss at step 90000: 5.0876162379980086\n",
      "2018-11-25 10:22:19,850 - DEBUG: Time Elapsed: 4.95500084956487 minutes\n",
      "2018-11-25 10:22:19,850 - DEBUG: Time Elapsed: 4.95500084956487 minutes\n",
      "2018-11-25 10:22:19,902 - DEBUG: Nearest to 1: chorus, 2, UNK, a-ask, corinna, inda, ching-a-ling, whoomp,\n",
      "2018-11-25 10:22:19,902 - DEBUG: Nearest to 1: chorus, 2, UNK, a-ask, corinna, inda, ching-a-ling, whoomp,\n",
      "2018-11-25 10:22:19,912 - DEBUG: Nearest to well: 's, a-ask, corinna, inda, doo-ah, whoomp, aum, hooligans,\n",
      "2018-11-25 10:22:19,912 - DEBUG: Nearest to well: 's, a-ask, corinna, inda, doo-ah, whoomp, aum, hooligans,\n",
      "2018-11-25 10:22:19,919 - DEBUG: Nearest to heart: love, inda, doo-ah, hooligans, a-ask, aum, do-be-da, animator,\n",
      "2018-11-25 10:22:19,919 - DEBUG: Nearest to heart: love, inda, doo-ah, hooligans, a-ask, aum, do-be-da, animator,\n",
      "2018-11-25 10:22:19,926 - DEBUG: Nearest to life: a-ask, 's, inda, whoomp, aum, hooligans, corinna, lucinda,\n",
      "2018-11-25 10:22:19,926 - DEBUG: Nearest to life: a-ask, 's, inda, whoomp, aum, hooligans, corinna, lucinda,\n",
      "2018-11-25 10:22:19,932 - DEBUG: Nearest to 're: 'm, a-ask, 's, whoomp, hooligans, kishka, doo-ah, know,\n",
      "2018-11-25 10:22:19,932 - DEBUG: Nearest to 're: 'm, a-ask, 's, whoomp, hooligans, kishka, doo-ah, know,\n",
      "2018-11-25 10:22:19,938 - DEBUG: Nearest to la: de, saboreando, libe, que, rainman, a-ask, chiquitita, oho,\n",
      "2018-11-25 10:22:19,938 - DEBUG: Nearest to la: de, saboreando, libe, que, rainman, a-ask, chiquitita, oho,\n",
      "2018-11-25 10:22:19,943 - DEBUG: Nearest to wan: na, gon, want, pao, corinna, inda, whoomp, a-ask,\n",
      "2018-11-25 10:22:19,943 - DEBUG: Nearest to wan: na, gon, want, pao, corinna, inda, whoomp, a-ask,\n",
      "2018-11-25 10:22:19,948 - DEBUG: Nearest to en: de, la, el, aum, libe, saboreando, kishka, lucinda,\n",
      "2018-11-25 10:22:19,948 - DEBUG: Nearest to en: de, la, el, aum, libe, saboreando, kishka, lucinda,\n",
      "2018-11-25 10:22:19,953 - DEBUG: Nearest to cause: know, a-ask, pao, n't, UNK, inda, zimbo, get,\n",
      "2018-11-25 10:22:19,953 - DEBUG: Nearest to cause: know, a-ask, pao, n't, UNK, inda, zimbo, get,\n",
      "2018-11-25 10:22:19,957 - DEBUG: Nearest to would: could, never, 'd, n't, kamarage, a-ask, pao, inda,\n",
      "2018-11-25 10:22:19,957 - DEBUG: Nearest to would: could, never, 'd, n't, kamarage, a-ask, pao, inda,\n",
      "2018-11-25 10:22:19,962 - DEBUG: Nearest to find: way, see, lucinda, UNK, a-ask, n't, inda, doo-ah,\n",
      "2018-11-25 10:22:19,962 - DEBUG: Nearest to find: way, see, lucinda, UNK, a-ask, n't, inda, doo-ah,\n",
      "2018-11-25 10:22:19,966 - DEBUG: Nearest to around: chiqui, aum, doo-ah, saboreando, ching-a-ling, back, corinna, cumin,\n",
      "2018-11-25 10:22:19,966 - DEBUG: Nearest to around: chiqui, aum, doo-ah, saboreando, ching-a-ling, back, corinna, cumin,\n",
      "2018-11-25 10:22:19,971 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, chiqui, UNK, doo-ah, pao,\n",
      "2018-11-25 10:22:19,971 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, chiqui, UNK, doo-ah, pao,\n",
      "2018-11-25 10:22:19,977 - DEBUG: Nearest to know: inda, whoomp, a-ask, hooligans, want, do-be-da, pao, UNK,\n",
      "2018-11-25 10:22:19,977 - DEBUG: Nearest to know: inda, whoomp, a-ask, hooligans, want, do-be-da, pao, UNK,\n",
      "2018-11-25 10:22:19,982 - DEBUG: Nearest to 2: chorus, 1, UNK, corinna, ching-a-ling, rainman, a-ask, ghoul,\n",
      "2018-11-25 10:22:19,982 - DEBUG: Nearest to 2: chorus, 1, UNK, corinna, ching-a-ling, rainman, a-ask, ghoul,\n",
      "2018-11-25 10:22:19,987 - DEBUG: Nearest to que: de, saboreando, oho, libe, la, terminal, aum, iô,\n",
      "2018-11-25 10:22:19,987 - DEBUG: Nearest to que: de, saboreando, oho, libe, la, terminal, aum, iô,\n",
      "2018-11-25 10:22:26,514 - DEBUG: Average loss at step 92000: 5.076148509383201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 10:22:26,514 - DEBUG: Average loss at step 92000: 5.076148509383201\n",
      "2018-11-25 10:22:26,517 - DEBUG: Time Elapsed: 5.066127101580302 minutes\n",
      "2018-11-25 10:22:26,517 - DEBUG: Time Elapsed: 5.066127101580302 minutes\n",
      "2018-11-25 10:22:33,125 - DEBUG: Average loss at step 94000: 5.111923713445663\n",
      "2018-11-25 10:22:33,125 - DEBUG: Average loss at step 94000: 5.111923713445663\n",
      "2018-11-25 10:22:33,128 - DEBUG: Time Elapsed: 5.176307479540507 minutes\n",
      "2018-11-25 10:22:33,128 - DEBUG: Time Elapsed: 5.176307479540507 minutes\n",
      "2018-11-25 10:22:39,696 - DEBUG: Average loss at step 96000: 5.074449409872294\n",
      "2018-11-25 10:22:39,696 - DEBUG: Average loss at step 96000: 5.074449409872294\n",
      "2018-11-25 10:22:39,699 - DEBUG: Time Elapsed: 5.285823913415273 minutes\n",
      "2018-11-25 10:22:39,699 - DEBUG: Time Elapsed: 5.285823913415273 minutes\n",
      "2018-11-25 10:22:46,288 - DEBUG: Average loss at step 98000: 5.159196599721908\n",
      "2018-11-25 10:22:46,288 - DEBUG: Average loss at step 98000: 5.159196599721908\n",
      "2018-11-25 10:22:46,290 - DEBUG: Time Elapsed: 5.3956803719202675 minutes\n",
      "2018-11-25 10:22:46,290 - DEBUG: Time Elapsed: 5.3956803719202675 minutes\n",
      "2018-11-25 10:22:52,854 - DEBUG: Average loss at step 100000: 5.091752164125443\n",
      "2018-11-25 10:22:52,854 - DEBUG: Average loss at step 100000: 5.091752164125443\n",
      "2018-11-25 10:22:52,857 - DEBUG: Time Elapsed: 5.505120960871379 minutes\n",
      "2018-11-25 10:22:52,857 - DEBUG: Time Elapsed: 5.505120960871379 minutes\n",
      "2018-11-25 10:22:52,906 - DEBUG: Nearest to 1: 2, chorus, a-ask, corinna, inda, libe, ching-a-ling, do-be-da,\n",
      "2018-11-25 10:22:52,906 - DEBUG: Nearest to 1: 2, chorus, a-ask, corinna, inda, libe, ching-a-ling, do-be-da,\n",
      "2018-11-25 10:22:52,911 - DEBUG: Nearest to well: a-ask, corinna, 's, inda, doo-ah, whoomp, know, pao,\n",
      "2018-11-25 10:22:52,911 - DEBUG: Nearest to well: a-ask, corinna, 's, inda, doo-ah, whoomp, know, pao,\n",
      "2018-11-25 10:22:52,915 - DEBUG: Nearest to heart: inda, love, doo-ah, whoomp, aum, hooligans, a-ask, animator,\n",
      "2018-11-25 10:22:52,915 - DEBUG: Nearest to heart: inda, love, doo-ah, whoomp, aum, hooligans, a-ask, animator,\n",
      "2018-11-25 10:22:52,919 - DEBUG: Nearest to life: a-ask, saboreando, corinna, inda, 's, hooligans, lucinda, aum,\n",
      "2018-11-25 10:22:52,919 - DEBUG: Nearest to life: a-ask, saboreando, corinna, inda, 's, hooligans, lucinda, aum,\n",
      "2018-11-25 10:22:52,924 - DEBUG: Nearest to 're: 'm, know, 's, doo-ah, inda, hooligans, a-ask, na,\n",
      "2018-11-25 10:22:52,924 - DEBUG: Nearest to 're: 'm, know, 's, doo-ah, inda, hooligans, a-ask, na,\n",
      "2018-11-25 10:22:52,928 - DEBUG: Nearest to la: bahm, de, saboreando, libe, noelia, inda, whoomp, rainman,\n",
      "2018-11-25 10:22:52,928 - DEBUG: Nearest to la: bahm, de, saboreando, libe, noelia, inda, whoomp, rainman,\n",
      "2018-11-25 10:22:52,932 - DEBUG: Nearest to wan: na, gon, want, know, pao, corinna, inda, whoomp,\n",
      "2018-11-25 10:22:52,932 - DEBUG: Nearest to wan: na, gon, want, know, pao, corinna, inda, whoomp,\n",
      "2018-11-25 10:22:52,936 - DEBUG: Nearest to en: de, la, bahm, el, aum, libe, whoomp, chiquitita,\n",
      "2018-11-25 10:22:52,936 - DEBUG: Nearest to en: de, la, bahm, el, aum, libe, whoomp, chiquitita,\n",
      "2018-11-25 10:22:52,941 - DEBUG: Nearest to cause: know, pao, a-ask, inda, doo-ah, zimbo, get, do-be-da,\n",
      "2018-11-25 10:22:52,941 - DEBUG: Nearest to cause: know, pao, a-ask, inda, doo-ah, zimbo, get, do-be-da,\n",
      "2018-11-25 10:22:52,945 - DEBUG: Nearest to would: could, 'd, a-ask, never, kamarage, inda, n't, pao,\n",
      "2018-11-25 10:22:52,945 - DEBUG: Nearest to would: could, 'd, a-ask, never, kamarage, inda, n't, pao,\n",
      "2018-11-25 10:22:52,949 - DEBUG: Nearest to find: way, lucinda, a-ask, see, aum, do-be-da, inda, doo-ah,\n",
      "2018-11-25 10:22:52,949 - DEBUG: Nearest to find: way, lucinda, a-ask, see, aum, do-be-da, inda, doo-ah,\n",
      "2018-11-25 10:22:52,954 - DEBUG: Nearest to around: chiqui, aum, doo-ah, saboreando, ching-a-ling, back, corinna, inda,\n",
      "2018-11-25 10:22:52,954 - DEBUG: Nearest to around: chiqui, aum, doo-ah, saboreando, ching-a-ling, back, corinna, inda,\n",
      "2018-11-25 10:22:52,959 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, chiqui, saboreando, doo-ah, pao,\n",
      "2018-11-25 10:22:52,959 - DEBUG: Nearest to look: see, a-ask, aum, do-be-da, chiqui, saboreando, doo-ah, pao,\n",
      "2018-11-25 10:22:52,963 - DEBUG: Nearest to know: whoomp, inda, pao, doo-ah, want, hooligans, a-ask, corinna,\n",
      "2018-11-25 10:22:52,963 - DEBUG: Nearest to know: whoomp, inda, pao, doo-ah, want, hooligans, a-ask, corinna,\n",
      "2018-11-25 10:22:52,967 - DEBUG: Nearest to 2: 1, chorus, corinna, rainman, ching-a-ling, a-ask, ghoul, loyola,\n",
      "2018-11-25 10:22:52,967 - DEBUG: Nearest to 2: 1, chorus, corinna, rainman, ching-a-ling, a-ask, ghoul, loyola,\n",
      "2018-11-25 10:22:52,972 - DEBUG: Nearest to que: de, bahm, saboreando, aum, te, rainman, whoomp, chiquitita,\n",
      "2018-11-25 10:22:52,972 - DEBUG: Nearest to que: de, bahm, saboreando, aum, te, rainman, whoomp, chiquitita,\n",
      "2018-11-25 10:22:53,151 - INFO: Time Elapsed: 5.510026160875956 minutes\n",
      "2018-11-25 10:22:53,151 - INFO: Time Elapsed: 5.510026160875956 minutes\n",
      "2018-11-25 10:22:53,245 - DEBUG: pickled <class 'numpy.ndarray'> to logs/tf/lyrics2vec_embeddings.pickle\n",
      "2018-11-25 10:22:53,245 - DEBUG: pickled <class 'numpy.ndarray'> to logs/tf/lyrics2vec_embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "lyrics_vectorizer.train(\n",
    "    V=lyrics2vec.VOCAB_SIZE,\n",
    "    batch_size=128,\n",
    "    embedding_size=300,\n",
    "    skip_window=4,\n",
    "    num_skips=2,\n",
    "    num_sampled=64\n",
    ")\n",
    "lyrics_vectorizer.save_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 09:12:44,796 - INFO: Beginning label plotting\n",
      "2018-11-25 09:12:44,796 - INFO: Beginning label plotting\n",
      "2018-11-25 09:20:47,172 - INFO: Elapsed Time: 8.039559098084768\n",
      "2018-11-25 09:20:47,172 - INFO: Elapsed Time: 8.039559098084768\n",
      "2018-11-25 09:20:47,174 - INFO: saved plot at logs/tf/2018-11-25_09-12-44_embeddings.png\n",
      "2018-11-25 09:20:47,174 - INFO: saved plot at logs/tf/2018-11-25_09-12-44_embeddings.png\n"
     ]
    }
   ],
   "source": [
    "embeddings_png = os.path.join(\n",
    "    lyrics2vec.LOGS_TF_DIR, \n",
    "    '{0}_{1}'.format(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'), 'embeddings.png'))\n",
    "lyrics_vectorizer.plot_with_labels(embeddings_png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](logs/tf/2018-11-25_09-12-44_embeddings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics2vec Optimizations\n",
    "\n",
    "Because generating the vocabulary takes 6+ minutes and training the word embeddings takes 5 minutes, we've enabled several optimizations in the lyrics2vec class.\n",
    "\n",
    "1. Vocabulary Saving\n",
    "2. Dataset Pickling\n",
    "3. Embedding Saving\n",
    "\n",
    "lyrics2vec contains functions to do each of the above so that you only have to do each step once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 09:29:11,356 - DEBUG: pickled <class 'list'> to logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:29:11,356 - DEBUG: pickled <class 'list'> to logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:29:11,411 - DEBUG: pickled <class 'list'> to logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:29:11,411 - DEBUG: pickled <class 'list'> to logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:29:11,439 - DEBUG: pickled <class 'dict'> to logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:29:11,439 - DEBUG: pickled <class 'dict'> to logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:29:11,451 - DEBUG: pickled <class 'dict'> to logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:29:11,451 - DEBUG: pickled <class 'dict'> to logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:29:11,452 - INFO: datasets successfully pickled\n",
      "2018-11-25 09:29:11,452 - INFO: datasets successfully pickled\n",
      "2018-11-25 09:29:11,486 - DEBUG: pickled <class 'numpy.ndarray'> to logs/tf/lyrics2vec_embeddings.pickle\n",
      "2018-11-25 09:29:11,486 - DEBUG: pickled <class 'numpy.ndarray'> to logs/tf/lyrics2vec_embeddings.pickle\n"
     ]
    }
   ],
   "source": [
    "# vocabulary.txt was already saved as part of the extract_words step\n",
    "# save datasets\n",
    "lyrics_vectorizer.save_datasets()\n",
    "# save word embeddings\n",
    "lyrics_vectorizer.save_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also functions to let you pick up where you left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 09:29:59,722 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:29:59,722 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:30:00,378 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:30:00,378 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:30:00,395 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:30:00,395 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:30:00,404 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:30:00,404 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:30:00,418 - INFO: datasets successfully loaded via pickle\n",
      "2018-11-25 09:30:00,418 - INFO: datasets successfully loaded via pickle\n",
      "2018-11-25 09:30:00,438 - DEBUG: unpickled <class 'numpy.ndarray'> from logs/tf/lyrics2vec_embeddings.pickle\n",
      "2018-11-25 09:30:00,438 - DEBUG: unpickled <class 'numpy.ndarray'> from logs/tf/lyrics2vec_embeddings.pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_vectorizer.load_datasets()\n",
    "lyrics_vectorizer.load_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, the vocabulary and dataset can be loaded all in one go with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-25 09:30:46,179 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:30:46,179 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_data.pickle\n",
      "2018-11-25 09:30:46,700 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:30:46,700 - DEBUG: unpickled <class 'list'> from logs/tf/lyrics2vec_count.pickle\n",
      "2018-11-25 09:30:46,712 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:30:46,712 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_dict.pickle\n",
      "2018-11-25 09:30:46,721 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:30:46,721 - DEBUG: unpickled <class 'dict'> from logs/tf/lyrics2vec_revdict.pickle\n",
      "2018-11-25 09:30:46,722 - INFO: datasets successfully loaded via pickle\n",
      "2018-11-25 09:30:46,722 - INFO: datasets successfully loaded via pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lyrics2vec()>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics2vec.lyrics2vec.InitFromLyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_w266_project",
   "language": "python",
   "name": ".venv_w266_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
