{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyric Mood Classification - Mood Classification\n",
    "\n",
    "In the [word_embeddings](word_embeddings.ipynb) notebook, we demonstrated our embeddings model based on word2vec. In this notebook, we use those embeddings to produce real classification results with a neural network.\n",
    "\n",
    "First, we split our labeled data into the classic train-dev-test split.\n",
    "\n",
    "Second, we establish a baseline classification with simple classifiers.\n",
    "\n",
    "Third, we demonstrate our neural network architecture and model for mood classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Imports\n",
    "from index_lyrics import read_file_contents\n",
    "from label_lyrics import CSV_LABELED_LYRICS\n",
    "from scrape_lyrics import LYRICS_TXT_DIR\n",
    "from lyrics2vec import lyrics2vec\n",
    "\n",
    "# Python and Package Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lyrics2vec\n",
    "import datetime\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset consists of a large number of text files where each file represents a different song. The songs are indexed by a csv file produced by `label_lyrics.py`. We can use the index to retrieve a song's lyrics and observe its matched mood.\n",
    "\n",
    "We drop all songs that are not english, do not have lyrics available, and do not have a matched mood as classifying across languages is out of scope of this project and no classification can be done on a song without lyrics or without a matched mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcworkma/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['found_tags', 'is_english', 'lyrics_available', 'lyrics_filename',\n",
       "       'matched_mood', 'mood', 'msd_artist', 'msd_id', 'msd_title',\n",
       "       'wordcount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we leave out the musixmatch id, artist, and title cols\n",
    "df = pd.read_csv('data/labeled_lyrics_expanded.csv', usecols=['msd_id', 'msd_artist', 'msd_title', 'is_english', 'lyrics_available', 'wordcount', 'lyrics_filename', 'mood', 'found_tags', 'matched_mood'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df shape: (779056, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>found_tags</th>\n",
       "      <th>is_english</th>\n",
       "      <th>lyrics_available</th>\n",
       "      <th>matched_mood</th>\n",
       "      <th>wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>779056.000000</td>\n",
       "      <td>779056.000000</td>\n",
       "      <td>779056.000000</td>\n",
       "      <td>779056.000000</td>\n",
       "      <td>779056.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.870052</td>\n",
       "      <td>0.342566</td>\n",
       "      <td>0.420039</td>\n",
       "      <td>-0.575658</td>\n",
       "      <td>87.716389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>19.502538</td>\n",
       "      <td>0.474571</td>\n",
       "      <td>0.493565</td>\n",
       "      <td>0.638805</td>\n",
       "      <td>141.151970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>161.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8623.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          found_tags     is_english  lyrics_available   matched_mood  \\\n",
       "count  779056.000000  779056.000000     779056.000000  779056.000000   \n",
       "mean        5.870052       0.342566          0.420039      -0.575658   \n",
       "std        19.502538       0.474571          0.493565       0.638805   \n",
       "min        -1.000000      -1.000000          0.000000      -1.000000   \n",
       "25%        -1.000000       0.000000          0.000000      -1.000000   \n",
       "50%        -1.000000       0.000000          0.000000      -1.000000   \n",
       "75%         1.000000       1.000000          1.000000       0.000000   \n",
       "max       100.000000       1.000000          1.000000       1.000000   \n",
       "\n",
       "           wordcount  \n",
       "count  779056.000000  \n",
       "mean       87.716389  \n",
       "std       141.151970  \n",
       "min        -1.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%       161.000000  \n",
       "max      8623.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Df shape:', df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After is_english filter: (266879, 10)\n",
      "After lyrics_available filter: (266783, 10)\n",
      "After matched_mood filter: (63803, 10)\n"
     ]
    }
   ],
   "source": [
    "df = df[df.is_english == 1]\n",
    "print('After is_english filter:', df.shape)\n",
    "df = df[df.lyrics_available == 1]\n",
    "print('After lyrics_available filter:', df.shape)\n",
    "df = df[df.matched_mood == 1]\n",
    "print('After matched_mood filter:', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove no longer needed columns to conserve memory\n",
    "df = df.drop(['is_english', 'lyrics_available', 'matched_mood'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4  7 15  2  5 17 16 11  1  0 13 12  9  8  3  6 10 14]\n",
      "(63803, 8)\n"
     ]
    }
   ],
   "source": [
    "# create a categorical data column for moods\n",
    "# thank you: https://stackoverflow.com/questions/38088652/pandas-convert-categories-to-numbers\n",
    "df.mood = pd.Categorical(df.mood)\n",
    "df['mood_cats'] = df.mood.cat.codes\n",
    "print(df['mood_cats'].unique())\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     And Oceans\\nMiscellaneous\\nNew Model World\\n[i...\n",
       "7     Electro eroticism\\nIntelligence is sexy\\nElect...\n",
       "17    You fight just for the sake of it\\nYou know wh...\n",
       "19    I'm in the dark, I'd like to read his mind\\nBu...\n",
       "25    There was a time\\nYou opened up every doorway\\...\n",
       "Name: lyrics, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the lyrics of each song\n",
    "def extract_lyrics(lyrics_filepath):\n",
    "    lyrics = ''\n",
    "    if os.path.exists(lyrics_filepath):\n",
    "        lyrics = read_file_contents(lyrics_filepath)[0]\n",
    "    return lyrics\n",
    "\n",
    "def make_lyrics_txt_path(lyrics_filename):\n",
    "    return os.path.join(LYRICS_TXT_DIR, lyrics_filename) + '.txt'\n",
    "\n",
    "# here we make use of panda's apply function to parallelize the IO operation\n",
    "df['lyrics'] = df.lyrics_filename.apply(lambda x: extract_lyrics(make_lyrics_txt_path(x)))\n",
    "df.lyrics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final number of songs with a matched mood: 63803\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('The final number of songs with a matched mood:', df.shape[0])\n",
    "_ = df.mood.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calm          25502\n",
       "sad            9397\n",
       "depressed      7242\n",
       "happy          5828\n",
       "upbeat         4124\n",
       "anger          3723\n",
       "romantic       3051\n",
       "angst          1694\n",
       "cheerful        832\n",
       "aggression      580\n",
       "grief           560\n",
       "desire          397\n",
       "confident       219\n",
       "excitement      210\n",
       "brooding        187\n",
       "earnest         107\n",
       "pessimism        90\n",
       "dreamy           60\n",
       "Name: mood, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mood.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Dev, & Test\n",
    "\n",
    "With our dataset index in hand, we are prepared to split the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thank you: https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test/38251213#38251213\n",
    "# optional random dataframe shuffle\n",
    "#df = df.reindex(np.random.permutation(df.index))\n",
    "np.random.seed(12)\n",
    "def split_data(data):\n",
    "    return np.split(data.sample(frac=1), [int(.6*len(data)), int(.8*len(data))])\n",
    "\n",
    "df_train, df_dev, df_test = split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (38281, 9)\n",
      "Dev: (12761, 9)\n",
      "Test: (12761, 9)\n"
     ]
    }
   ],
   "source": [
    "print('Train:', df_train.shape)\n",
    "print('Dev:', df_dev.shape)\n",
    "print('Test:', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# thank you: https://stackoverflow.com/questions/14992644/turn-pandas-dataframe-of-strings-into-histogram\n",
    "_ = df_train.mood.value_counts().plot(kind='bar', title='Train Dataset Mood Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = df_dev.mood.value_counts().plot(kind='bar', title='Dev Dataset Mood Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = df_test.mood.value_counts().plot(kind='bar', title='Test Dataset Mood Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most-Common-Case Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pprint_accuracy(acc):\n",
    "    return '{0:.02f}%'.format(acc * 100)\n",
    "\n",
    "def most_common_case_classification(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    total_count = len(x)\n",
    "    common_count = y.value_counts().max()\n",
    "    accuracy = common_count / total_count\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common case for each dataset split is\n",
      "\tTrain: calm\n",
      "\tDev: calm\n",
      "\tTest: calm\n",
      "The accuracy of the most-common-case classifier for each dataset split is\n",
      "\tTrain: 40.02%\n",
      "\tDev: 40.54%\n",
      "\tTest: 39.24%\n"
     ]
    }
   ],
   "source": [
    "print('The most common case for each dataset split is')\n",
    "print('\\tTrain:', df_train.mood.value_counts().idxmax())\n",
    "print('\\tDev:', df_dev.mood.value_counts().idxmax())\n",
    "print('\\tTest:', df_test.mood.value_counts().idxmax())\n",
    "#df_test.loc[df_test.mood_classes.idxmax()].mood\n",
    "print('The accuracy of the most-common-case classifier for each dataset split is')\n",
    "print('\\tTrain:', pprint_accuracy(most_common_case_classification(df_train.lyrics_filename, df_train.mood)))\n",
    "print('\\tDev:', pprint_accuracy(most_common_case_classification(df_dev.lyrics_filename, df_dev.mood)))\n",
    "print('\\tTest:', pprint_accuracy(most_common_case_classification(df_test.lyrics_filename, df_test.mood)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive-Bayes Classification\n",
    "\n",
    "The Naive-Bayes Classifier will require the actual lyrical text for classification, so we begin by reading into memory the text for each song in our dataset.\n",
    "\n",
    "Once we have the lyrics, we use the python sklearn package to vectorize and process the lyrical text, fit the Naive Bayes Classifier, and compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38281, 62247)\n",
      "(12761, 62247)\n",
      "(12761, 62247)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "def prep_lyrics_for_nb(lyrics_series, count_vect=None, tfidf_transformer=None):\n",
    "   # thank you: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "    if not count_vect:\n",
    "        count_vect = CountVectorizer()\n",
    "        count_vect = count_vect.fit(lyrics_series)\n",
    "    x_train_counts = count_vect.transform(lyrics_series)\n",
    "    if not tfidf_transformer:\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        tfidf_transformer = tfidf_transformer.fit(x_train_counts)\n",
    "    x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
    "    return count_vect, x_train_counts, tfidf_transformer, x_train_tfidf\n",
    "\n",
    "# convert lyrics to counts and term-frequencies\n",
    "count_vect, x_train_counts, tfidf_transformer, x_train_tfidf = prep_lyrics_for_nb(df_train.lyrics)\n",
    "print(x_train_tfidf.shape)\n",
    "_, x_dev_counts, _, x_dev_tfidf = prep_lyrics_for_nb(df_dev.lyrics, count_vect, tfidf_transformer)\n",
    "print(x_dev_tfidf.shape)\n",
    "_, x_test_counts, _, x_test_tfidf = prep_lyrics_for_nb(df_test.lyrics, count_vect, tfidf_transformer)\n",
    "print(x_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Dev Accuracy: 40.76%\n",
      "Naive Bayes Classifier Test Accuracy: 39.39%\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(x_train_tfidf, df_train.mood_cats) \n",
    "dev_acc = clf.score(x_dev_tfidf, df_dev.mood_cats)\n",
    "print('Naive Bayes Classifier Dev Accuracy:', pprint_accuracy(dev_acc))\n",
    "test_acc = clf.score(x_test_tfidf, df_test.mood_cats)\n",
    "print('Naive Bayes Classifier Test Accuracy:', pprint_accuracy(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Classification\n",
    "\n",
    "From [Corona & O'Mahony](https://www.researchgate.net/publication/280733696_An_Exploration_of_Mood_Classification_in_the_Million_Songs_Dataset), SVMs have been used with success in this area. Here we see that they do provide a sizeable increase in accuracy over NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Dev Accuracy: 45.40%\n",
      "SVM Classifier Test Accuracy: 44.39%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42,\n",
    "            max_iter=5, tol=None).fit(x_train_tfidf, df_train.mood_cats)\n",
    "dev_acc = clf.score(x_dev_tfidf, df_dev.mood_cats)\n",
    "print('SVM Classifier Dev Accuracy:', pprint_accuracy(dev_acc))\n",
    "test_acc = clf.score(x_test_tfidf, df_test.mood_cats)\n",
    "print('SVM Classifier Test Accuracy:', pprint_accuracy(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN\n",
    "\n",
    "http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/\n",
    "\n",
    "CNNs process textual input different than a Naive Bayes or SVM classifier. We perform the following data processing steps on all lyrics:\n",
    "* Truncate/extend all songs to the 75% wordcount percentile\n",
    "* Tokenize lyrics with nltk's word_tokenize function\n",
    "* Remove all stopwords that match from within nltk's stopwords corpus\n",
    "* Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    63803.000000\n",
      "mean       231.658982\n",
      "std        139.035896\n",
      "min          1.000000\n",
      "25%        143.000000\n",
      "50%        204.000000\n",
      "75%        282.000000\n",
      "max       2913.000000\n",
      "Name: wordcount, dtype: float64\n",
      "\n",
      "All songs will be limited to 282 words\n"
     ]
    }
   ],
   "source": [
    "pctiles = df.wordcount.describe()\n",
    "print(pctiles)\n",
    "cutoff = int(pctiles[pctiles.index.str.startswith('75%')][0])\n",
    "print('\\nAll songs will be limited to {0} words'.format(cutoff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(lyrics2vec)\n",
    "lyrics_vectorizer = lyrics2vec.lyrics2vec.InitFromLyrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data normalized (0.8257552981376648 minutes)\n",
      "228247    [526, 43, 99, 5, 15, 77, 234, 179, 19, 86, 383...\n",
      "214654    [37, 93, 868, 3364, 2, 12, 596, 1668, 873, 4, ...\n",
      "175139    [71, 44, 297, 250, 2271, 1511, 127, 1310, 231,...\n",
      "58579     [37, 93, 1, 100, 382, 122, 181, 38, 162, 35, 1...\n",
      "196716    [253, 7, 43, 22, 1, 209, 209, 3, 147, 7, 94, 7...\n",
      "Name: normalized_lyrics, dtype: object\n",
      "dev data normalized (1.0960610191027322 minutes)\n",
      "149604    [315, 26, 8, 95, 280, 7, 136, 201, 5, 37330, 4...\n",
      "71942     [37, 93, 24, 68, 1462, 12, 213, 6044, 43, 231,...\n",
      "91524     [37, 93, 269, 14574, 130, 1032, 1107, 6, 1467,...\n",
      "238415    [37, 93, 60, 245, 800, 2179, 0, 288, 250, 0, 1...\n",
      "162087    [37, 143, 1495, 143, 146, 48086, 14761, 391, 4...\n",
      "Name: normalized_lyrics, dtype: object\n",
      "test data normalized (1.3717837452888488 minutes)\n",
      "248608    [24, 26, 12, 766, 7, 222, 6, 45, 2295, 1402, 2...\n",
      "240285    [99, 212, 99, 99, 315, 124, 1840, 194, 235, 33...\n",
      "200631    [15, 294, 3904, 656, 193, 1133, 193, 4136, 291...\n",
      "187697    [3866, 856, 23149, 334, 3869, 306, 0, 2540, 22...\n",
      "83000     [37, 93, 27, 667, 15, 8, 31, 3065, 27, 12, 330...\n",
      "Name: normalized_lyrics, dtype: object\n",
      "\n",
      "Example of padding:\n",
      "\tFirst 5 tokens: [526, 43, 99, 5, 15]\n",
      "\tLast 5 tokens: [0, 0, 0, 0, 0].\n",
      "\n",
      "Elapsed Time: 1.3720292687416076 minutes\n"
     ]
    }
   ],
   "source": [
    "def normalize_lyrics(lyrics, max_length, lyrics_vectorizer):\n",
    "    \"\"\"\n",
    "    Tokenize, process, shorten/lengthen, and vectorize lyrics\n",
    "    \"\"\"\n",
    "    lyrics = lyrics2vec.lyrics_preprocessing(lyrics)\n",
    "    if len(lyrics) > max_length:\n",
    "        lyrics = lyrics[:max_length]\n",
    "    else:\n",
    "        lyrics += ['<PAD>'] * (int(max_length) - int(len(lyrics)))\n",
    "\n",
    "    lyric_vector = lyrics_vectorizer.transform(lyrics)\n",
    "    return lyric_vector\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# here we make use of panda's apply function to parallelize the IO operation (again)\n",
    "df_train['normalized_lyrics'] = df_train.lyrics.apply(lambda x: normalize_lyrics(x, cutoff, lyrics_vectorizer))\n",
    "print('train data normalized ({0} minutes)'.format((time.time() - start) / 60))\n",
    "print(df_train.normalized_lyrics.head())\n",
    "\n",
    "df_dev['normalized_lyrics'] = df_dev.lyrics.apply(lambda x: normalize_lyrics(x, cutoff, lyrics_vectorizer))\n",
    "print('dev data normalized ({0} minutes)'.format((time.time() - start) / 60))\n",
    "print(df_dev.normalized_lyrics.head())\n",
    "\n",
    "df_test['normalized_lyrics'] = df_test.lyrics.apply(lambda x: normalize_lyrics(x, cutoff, lyrics_vectorizer))\n",
    "print('test data normalized ({0} minutes)'.format((time.time() - start) / 60))\n",
    "print(df_test.normalized_lyrics.head())\n",
    "\n",
    "print('\\nExample of padding:')\n",
    "example = df_train.normalized_lyrics[df_train.normalized_lyrics.str.len() == cutoff].iloc[0]\n",
    "print('\\tFirst 5 tokens: {0}'.format(example[:5]))\n",
    "print('\\tLast 5 tokens: {0}.'.format(example[-5:]))\n",
    "\n",
    "print('\\nElapsed Time: {0} minutes'.format((time.time() - start) / 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Following code is borrowed from [this excellent and very helpful blog post](http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/) to PoC the validity of the preprocessed tokens and word embeddings**\n",
    "\n",
    "\n",
    "And here's a walkthrough of that blog post's code: https://agarnitin86.github.io/blog/2016/12/23/text-classification-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(object):\n",
    "    \"\"\"\n",
    "    A CNN for text classification.\n",
    "    Uses an embedding layer, followed by a convolutional, max-pooling and softmax layer.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "      self, sequence_length, num_classes, vocab_size,\n",
    "      embedding_size, filter_sizes, num_filters, l2_reg_lambda=0.0,\n",
    "      embeddings=None):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # Embedding layer\n",
    "        # for loading word2vec: https://stackoverflow.com/questions/35687678/using-a-pre-trained-word-embedding-word2vec-or-glove-in-tensorflow\n",
    "        with tf.device('/cpu:0'), tf.name_scope(\"embedding\"):\n",
    "\n",
    "            self.pretrained_embeddings = embeddings is not None\n",
    "            if self.pretrained_embeddings:\n",
    "                self.W = tf.get_variable(\n",
    "                    shape=embeddings.shape,\n",
    "                    initializer=tf.constant_initializer(embeddings),\n",
    "                    trainable=True,\n",
    "                    name=\"W\")\n",
    "            else:\n",
    "                self.W = tf.Variable(\n",
    "                    tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                    name=\"W\")\n",
    "            \n",
    "            self.embedded_chars = tf.nn.embedding_lookup(self.W, self.input_x)\n",
    "            self.embedded_chars_expanded = tf.expand_dims(self.embedded_chars, -1)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        pooled_outputs = []\n",
    "        for i, filter_size in enumerate(filter_sizes):\n",
    "            with tf.name_scope(\"conv-maxpool-%s\" % filter_size):\n",
    "                # Convolution Layer\n",
    "                filter_shape = [filter_size, embedding_size, 1, num_filters]\n",
    "                Wconv = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.1), name=\"Wconv\")\n",
    "                b = tf.Variable(tf.constant(0.1, shape=[num_filters]), name=\"b\")\n",
    "                conv = tf.nn.conv2d(\n",
    "                    self.embedded_chars_expanded,\n",
    "                    Wconv,\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding=\"VALID\",\n",
    "                    name=\"conv\")\n",
    "                # Apply nonlinearity\n",
    "                h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "                # Maxpooling over the outputs\n",
    "                pooled = tf.nn.max_pool(\n",
    "                    h,\n",
    "                    ksize=[1, sequence_length - filter_size + 1, 1, 1],\n",
    "                    strides=[1, 1, 1, 1],\n",
    "                    padding='VALID',\n",
    "                    name=\"pool\")\n",
    "                pooled_outputs.append(pooled)\n",
    "\n",
    "        # Combine all the pooled features\n",
    "        num_filters_total = num_filters * len(filter_sizes)\n",
    "        self.h_pool = tf.concat(pooled_outputs, 3)\n",
    "        self.h_pool_flat = tf.reshape(self.h_pool, [-1, num_filters_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout\"):\n",
    "            self.h_drop = tf.nn.dropout(self.h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Final (unnormalized) scores and predictions\n",
    "        with tf.name_scope(\"output\"):\n",
    "            Wconv = tf.get_variable(\n",
    "                \"Wconv\",\n",
    "                shape=[num_filters_total, num_classes],\n",
    "                initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            l2_loss += tf.nn.l2_loss(Wconv)\n",
    "            l2_loss += tf.nn.l2_loss(b)\n",
    "            self.scores = tf.nn.xw_plus_b(self.h_drop, Wconv, b, name=\"scores\")\n",
    "            self.predictions = tf.argmax(self.scores, 1, name=\"predictions\")\n",
    "\n",
    "        # Calculate mean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=self.scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(self.predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_iter(data, batch_size, num_epochs, shuffle=True):\n",
    "    \"\"\"\n",
    "    Generates a batch iterator for a dataset.\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    data_size = len(data)\n",
    "    num_batches_per_epoch = int((len(data)-1)/batch_size) + 1\n",
    "    print('num_batches_per_epoch = {0}'.format(num_batches_per_epoch))\n",
    "    for epoch in range(num_epochs):\n",
    "        print('***********************************************')\n",
    "        print('Epoch {0}/{1}\\n'.format(epoch, num_epochs))\n",
    "        # Shuffle the data at each epoch\n",
    "        if shuffle:\n",
    "            shuffle_indices = np.random.permutation(np.arange(data_size))\n",
    "            shuffled_data = data[shuffle_indices]\n",
    "        else:\n",
    "            shuffled_data = data\n",
    "        for batch_num in range(num_batches_per_epoch):\n",
    "            print('-----------------------------------------------')\n",
    "            start_index = batch_num * batch_size\n",
    "            end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "            print('Epoch {0}/{1}, Batch {2}/{3} (start={4}, end={5})'.format(\n",
    "                epoch, num_epochs, batch_num, num_batches_per_epoch, start_index, end_index))\n",
    "            yield shuffled_data[start_index:end_index]\n",
    "            \n",
    "def train(vocab_size, x_train, y_train, x_dev, y_dev, x_test, y_test, train_embeddings=False, embeddings=None):\n",
    "    # Training\n",
    "    # ==================================================\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.ConfigProto()\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            cnn = TextCNN(\n",
    "                sequence_length=x_train.shape[1],\n",
    "                num_classes=y_train.shape[1],\n",
    "                #vocab_size=len(vocab_processor.vocabulary_),\n",
    "                vocab_size=vocab_size,\n",
    "                embedding_size=embedding_dim,\n",
    "                filter_sizes=filter_sizes,\n",
    "                num_filters=num_filters,\n",
    "                l2_reg_lambda=l2_reg_lambda,\n",
    "                embeddings=embeddings)\n",
    "\n",
    "            # Define Training procedure\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "            optimizer = tf.train.AdamOptimizer(1e-3)\n",
    "            grads_and_vars = optimizer.compute_gradients(cnn.loss)\n",
    "            train_op = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "            # Keep track of gradient values and sparsity (optional)\n",
    "            grad_summaries = []\n",
    "            for g, v in grads_and_vars:\n",
    "                if g is not None:\n",
    "                    grad_hist_summary = tf.summary.histogram(\"{}/grad/hist\".format(v.name), g)\n",
    "                    sparsity_summary = tf.summary.scalar(\"{}/grad/sparsity\".format(v.name), tf.nn.zero_fraction(g))\n",
    "                    grad_summaries.append(grad_hist_summary)\n",
    "                    grad_summaries.append(sparsity_summary)\n",
    "            grad_summaries_merged = tf.summary.merge(grad_summaries)\n",
    "\n",
    "            # Output directory for models and summaries\n",
    "            if USE_TIME_AS_KEY:\n",
    "                experiment_name = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "            else:\n",
    "                experiment_name = make_experiment_name()'Em-{0}_FS-{1}_NF-{2}_D-{3}_L2-{4}_B-{5}_Ep-{6}_W2V-{7}{8}_V-{9}'.format(\n",
    "                    embedding_dim, '-'.join(map(str, filter_sizes)),\n",
    "                    num_filters,\n",
    "                    dropout_keep_prob,\n",
    "                    l2_reg_lambda,\n",
    "                    batch_size,\n",
    "                    num_epochs,\n",
    "                    1 if cnn.pretrained_embeddings else 0,\n",
    "                    '-Tr' if train_embeddings else '',\n",
    "                    vocab_size)\n",
    "            out_dir = os.path.abspath(os.path.join(lyrics2vec.LOGS_TF_DIR, \"runs\", experiment_name))\n",
    "            os.makedirs(out_dir)\n",
    "            print(\"Writing to {}\\n\".format(out_dir))\n",
    "            \n",
    "            # dump params to json in case they need to be referenced later\n",
    "            with open(os.path.join(out_dir, 'model_params.json'), 'w') as outfile:\n",
    "                model_params = {\n",
    "                    'embedding_dim': embedding_dim,\n",
    "                    'filter_sizes': filter_sizes,\n",
    "                    'num_filters': num_filters,\n",
    "                    'dropout_keep_prob': dropout_keep_prob,\n",
    "                    'l2_reg_lambda': l2_reg_lambda,\n",
    "                    'batch_size': batch_size,\n",
    "                    'num_epochs': num_epochs,\n",
    "                    'evaluate_every': evaluate_every,\n",
    "                    'checkpoint_every': checkpoint_every,\n",
    "                    'num_checkpoints': num_checkpoints,\n",
    "                    'train_embeddings': train_embeddings,\n",
    "                    'pretrained_embeddings': cnn.pretrained_embeddings\n",
    "                }\n",
    "                json.dump(model_params, outfile, sort_keys=True)\n",
    "                \n",
    "            # Summaries for loss and accuracy\n",
    "            loss_summary = tf.summary.scalar(\"loss\", cnn.loss)\n",
    "            acc_summary = tf.summary.scalar(\"accuracy\", cnn.accuracy)\n",
    "\n",
    "            # Train Summaries\n",
    "            summary_dir = os.path.join(out_dir, \"summaries\")\n",
    "            train_summary_op = tf.summary.merge([loss_summary, acc_summary, grad_summaries_merged])\n",
    "            train_summary_writer = tf.summary.FileWriter(os.path.join(summary_dir, \"train\"), sess.graph)\n",
    "\n",
    "            # Dev summaries\n",
    "            dev_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            dev_summary_writer = tf.summary.FileWriter(os.path.join(summary_dir, \"dev\"), sess.graph)\n",
    "\n",
    "            # Test summaries\n",
    "            test_summary_op = tf.summary.merge([loss_summary, acc_summary])\n",
    "            test_summary_writer = tf.summary.FileWriter(os.path.join(summary_dir, \"test\"), sess.graph)\n",
    "            \n",
    "            # Checkpoint directory. Tensorflow assumes this directory already exists so we need to create it\n",
    "            checkpoint_dir = os.path.abspath(os.path.join(out_dir, \"checkpoints\"))\n",
    "            checkpoint_prefix = os.path.join(checkpoint_dir, \"model\")\n",
    "            if not os.path.exists(checkpoint_dir):\n",
    "                os.makedirs(checkpoint_dir)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=num_checkpoints)\n",
    "\n",
    "            # Write vocabulary\n",
    "            #vocab_processor.save(os.path.join(out_dir, \"vocab\"))\n",
    "\n",
    "            # Initialize all variables\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            def train_step(x_batch, y_batch, summary_writer=None, step_writer=None):\n",
    "                \"\"\"\n",
    "                A single training step\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: dropout_keep_prob\n",
    "                }\n",
    "                _, step, summaries, loss, accuracy = sess.run(\n",
    "                    [train_op, global_step, train_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                if summary_writer:\n",
    "                    summary_writer.add_summary(summaries, step)\n",
    "                if step_writer:\n",
    "                    step_writer.writerow(['train', time_str, step, loss, accuracy])\n",
    "                return time_str, step, loss, accuracy\n",
    "\n",
    "            def dev_step(x_batch, y_batch, summary_writer=None, step_writer=None):\n",
    "                \"\"\"\n",
    "                Evaluates model on a dev set\n",
    "                \"\"\"\n",
    "                feed_dict = {\n",
    "                  cnn.input_x: x_batch,\n",
    "                  cnn.input_y: y_batch,\n",
    "                  cnn.dropout_keep_prob: 1.0\n",
    "                }\n",
    "                step, summaries, loss, accuracy = sess.run(\n",
    "                    [global_step, dev_summary_op, cnn.loss, cnn.accuracy],\n",
    "                    feed_dict)\n",
    "                time_str = datetime.datetime.now().isoformat()\n",
    "                print(\"{}: step {}, loss {:g}, acc {:g}\".format(time_str, step, loss, accuracy))\n",
    "                if summary_writer:\n",
    "                    summary_writer.add_summary(summaries, step)\n",
    "                if step_writer:\n",
    "                    step_writer.writerow(['train', time_str, step, loss, accuracy])\n",
    "                return time_str, step, loss, accuracy\n",
    "                   \n",
    "            csvwriter = None\n",
    "            if SAVE_STEP_DATA:\n",
    "                csvfile = open(os.path.join(out_dir, 'step_data.csv'), 'w')\n",
    "                csvwriter = csv.writer(csvfile)\n",
    "                csvwriter.writerow(['dataset', 'time', 'step', 'loss', 'acc'])\n",
    "                \n",
    "            # Generate batches\n",
    "            batches = batch_iter(\n",
    "                list(zip(x_train, y_train)), batch_size, num_epochs)\n",
    "            # Training loop. For each batch...\n",
    "            for batch in batches:\n",
    "                x_batch, y_batch = zip(*batch)\n",
    "                train_step(x_batch, y_batch, summary_writer=train_summary_writer, step_writer=csvwriter)\n",
    "                current_step = tf.train.global_step(sess, global_step)\n",
    "                if current_step % evaluate_every == 0:\n",
    "                    print(\"\\nEvaluation:\")\n",
    "                    dev_step(x_dev, y_dev, summary_writer=dev_summary_writer, step_writer=csvwriter)\n",
    "                    print(\"\")\n",
    "                if current_step % checkpoint_every == 0:\n",
    "                    path = saver.save(sess, checkpoint_prefix, global_step=current_step)\n",
    "                    print(\"Saved model checkpoint to {}\\n\".format(path))\n",
    "                    \n",
    "            print(\"\\nFinal Test Evaluation:\")\n",
    "            dev_step(x_test, y_test, summary_writer=test_summary_writer, step_writer=csvwriter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape: (50000, 300)\n"
     ]
    }
   ],
   "source": [
    "# get our pre-trained word2vec embeddings\n",
    "lyrics_vectorizer = lyrics2vec.lyrics2vec()\n",
    "embeddings_loaded = lyrics_vectorizer.load_embeddings()\n",
    "if embeddings_loaded:\n",
    "    print('embeddings shape:', lyrics_vectorizer.final_embeddings.shape)\n",
    "else:\n",
    "    print('failed to load embeddings!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "# ==================================================\n",
    "\n",
    "SAVE_STEP_DATA = True\n",
    "USE_TIME_AS_KEY = False\n",
    "\n",
    "# Model Hyperparameters\n",
    "embedding_dim = 300\n",
    "filter_sizes = [3,4,5]\n",
    "num_filters = 4\n",
    "dropout_keep_prob = 0.5\n",
    "l2_reg_lambda = 0.01\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "evaluate_every = 100\n",
    "checkpoint_every = 100\n",
    "num_checkpoints = 5\n",
    "\n",
    "# tensorboard vars\n",
    "experiment_name = None\n",
    "\n",
    "\n",
    "def make_experiment_name(embedding_dim, filter_sizes, num_filters, dropout_keep_prob, l2_reg_lamda,\n",
    "                         batch_size, num_epochs, pretrained_embeddings, train_embeddings, vocab_size)\n",
    "    experiment_name = 'Em-{0}_FS-{1}_NF-{2}_D-{3}_L2-{4}_B-{5}_Ep-{6}_W2V-{7}{8}_V-{9}'.format(\n",
    "        embedding_dim,\n",
    "        '-'.join(map(str, filter_sizes)),\n",
    "        num_filters,\n",
    "        dropout_keep_prob,\n",
    "        l2_reg_lambda,\n",
    "        batch_size,\n",
    "        num_epochs,\n",
    "        1 if cnn.pretrained_embeddings else 0,\n",
    "        '-Tr' if train_embeddings else '',\n",
    "        vocab_size)\n",
    "    return experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w2v0:logs/tf/runs/Em-128_FS-3-4-5_NF-128_D-0.5_L2-0.01_B-64_Ep-20/summaries/,new:None\n",
      "TensorBoard 1.12.0 at http://workman-ubuntu-desk:6006 (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "def build_tensorboard_logdir(runs):\n",
    "    \"\"\"\n",
    "    Constructs a tensorboard command out of <runs>\n",
    "    Ex: !tensorboard --logdir \n",
    "        w2v0:logs/tf/runs/Em-128_FS-3-4-5_NF-128_D-0.5_L2-0.01_B-64_Ep-20/summaries/,\n",
    "        w2v0-moodexp:logs/tf/runs/Em-300_FS-3-4-5_NF-64_D-0.5_L2-0.01_B-64_Ep-20_W2V-0-Tr_V-50000/summaries/\n",
    "        \n",
    "    Args:\n",
    "        runs: list of tuples, each tuple is a run with (<name>, <path>)\n",
    "        \n",
    "    Returns: str, tensorboard logdir\n",
    "    \"\"\"\n",
    "    logdir = ''\n",
    "    for run in runs:\n",
    "        if len(run) != 2:\n",
    "            raise Exception('improperly formatted run: {0}'.format(runs))\n",
    "        name = run[0]\n",
    "        path = run[1]\n",
    "        logdir += '{0}:{1},'.format(name, path)\n",
    "    # remove final comma\n",
    "    logdir = logdir[:-1]\n",
    "    return logdir\n",
    "\n",
    "best = ('w2v0', 'logs/tf/runs/Em-128_FS-3-4-5_NF-128_D-0.5_L2-0.01_B-64_Ep-20/summaries/')\n",
    "tb_logdir = build_tensorboard_logdir([best, ('new', experiment_name)])\n",
    "print(tb_logdir)\n",
    "!tensorboard --logdir {tb_logdir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name W:0/grad/hist is illegal; using W_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name W:0/grad/sparsity is illegal; using W_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Wconv:0/grad/hist is illegal; using conv-maxpool-3/Wconv_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/Wconv:0/grad/sparsity is illegal; using conv-maxpool-3/Wconv_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/hist is illegal; using conv-maxpool-3/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-3/b:0/grad/sparsity is illegal; using conv-maxpool-3/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Wconv:0/grad/hist is illegal; using conv-maxpool-4/Wconv_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/Wconv:0/grad/sparsity is illegal; using conv-maxpool-4/Wconv_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/hist is illegal; using conv-maxpool-4/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-4/b:0/grad/sparsity is illegal; using conv-maxpool-4/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Wconv:0/grad/hist is illegal; using conv-maxpool-5/Wconv_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/Wconv:0/grad/sparsity is illegal; using conv-maxpool-5/Wconv_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/hist is illegal; using conv-maxpool-5/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name conv-maxpool-5/b:0/grad/sparsity is illegal; using conv-maxpool-5/b_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name Wconv:0/grad/hist is illegal; using Wconv_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name Wconv:0/grad/sparsity is illegal; using Wconv_0/grad/sparsity instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/hist is illegal; using output/b_0/grad/hist instead.\n",
      "INFO:tensorflow:Summary name output/b:0/grad/sparsity is illegal; using output/b_0/grad/sparsity instead.\n",
      "Writing to /home/jcworkma/jack/w266-group-project_lyric-mood-classification/logs/tf/runs/Em-300_FS-3-4-5_NF-4_D-0.5_L2-0.01_B-64_Ep-10_W2V-1_V-50000\n",
      "\n",
      "num_batches_per_epoch = 599\n",
      "***********************************************\n",
      "Epoch 0/10\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 0/599 (start=0, end=64)\n",
      "2018-11-27T12:57:26.219653: step 1, loss 3.02911, acc 0.078125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 1/599 (start=64, end=128)\n",
      "2018-11-27T12:57:26.521822: step 2, loss 2.94028, acc 0.078125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 2/599 (start=128, end=192)\n",
      "2018-11-27T12:57:26.802996: step 3, loss 2.95034, acc 0.140625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 3/599 (start=192, end=256)\n",
      "2018-11-27T12:57:27.086577: step 4, loss 2.92454, acc 0.078125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 4/599 (start=256, end=320)\n",
      "2018-11-27T12:57:27.374478: step 5, loss 2.97464, acc 0.046875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 5/599 (start=320, end=384)\n",
      "2018-11-27T12:57:27.676318: step 6, loss 2.92516, acc 0.125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 6/599 (start=384, end=448)\n",
      "2018-11-27T12:57:27.950353: step 7, loss 2.85502, acc 0.09375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 7/599 (start=448, end=512)\n",
      "2018-11-27T12:57:28.243935: step 8, loss 2.89795, acc 0.0625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 8/599 (start=512, end=576)\n",
      "2018-11-27T12:57:28.513338: step 9, loss 2.74933, acc 0.125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 9/599 (start=576, end=640)\n",
      "2018-11-27T12:57:28.779254: step 10, loss 2.8519, acc 0.125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 10/599 (start=640, end=704)\n",
      "2018-11-27T12:57:29.067777: step 11, loss 2.77678, acc 0.046875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 11/599 (start=704, end=768)\n",
      "2018-11-27T12:57:29.353402: step 12, loss 2.76703, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 12/599 (start=768, end=832)\n",
      "2018-11-27T12:57:29.648800: step 13, loss 2.76207, acc 0.125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 13/599 (start=832, end=896)\n",
      "2018-11-27T12:57:29.953375: step 14, loss 2.72884, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 14/599 (start=896, end=960)\n",
      "2018-11-27T12:57:30.248651: step 15, loss 2.71488, acc 0.15625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 15/599 (start=960, end=1024)\n",
      "2018-11-27T12:57:30.534759: step 16, loss 2.7719, acc 0.109375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 16/599 (start=1024, end=1088)\n",
      "2018-11-27T12:57:30.810620: step 17, loss 2.71523, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 17/599 (start=1088, end=1152)\n",
      "2018-11-27T12:57:31.106155: step 18, loss 2.75339, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 18/599 (start=1152, end=1216)\n",
      "2018-11-27T12:57:31.390809: step 19, loss 2.6676, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 19/599 (start=1216, end=1280)\n",
      "2018-11-27T12:57:31.659714: step 20, loss 2.5977, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 20/599 (start=1280, end=1344)\n",
      "2018-11-27T12:57:31.957628: step 21, loss 2.6098, acc 0.125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 21/599 (start=1344, end=1408)\n",
      "2018-11-27T12:57:32.226751: step 22, loss 2.56983, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 22/599 (start=1408, end=1472)\n",
      "2018-11-27T12:57:32.510550: step 23, loss 2.89422, acc 0.078125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 23/599 (start=1472, end=1536)\n",
      "2018-11-27T12:57:32.782914: step 24, loss 2.51974, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 24/599 (start=1536, end=1600)\n",
      "2018-11-27T12:57:33.081317: step 25, loss 2.62885, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 25/599 (start=1600, end=1664)\n",
      "2018-11-27T12:57:33.380418: step 26, loss 2.47753, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 26/599 (start=1664, end=1728)\n",
      "2018-11-27T12:57:33.664736: step 27, loss 2.73074, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 27/599 (start=1728, end=1792)\n",
      "2018-11-27T12:57:33.956112: step 28, loss 2.43971, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 28/599 (start=1792, end=1856)\n",
      "2018-11-27T12:57:34.232190: step 29, loss 2.61509, acc 0.15625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 29/599 (start=1856, end=1920)\n",
      "2018-11-27T12:57:34.516280: step 30, loss 2.53472, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 30/599 (start=1920, end=1984)\n",
      "2018-11-27T12:57:34.813211: step 31, loss 2.67746, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 31/599 (start=1984, end=2048)\n",
      "2018-11-27T12:57:35.079356: step 32, loss 2.53993, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 32/599 (start=2048, end=2112)\n",
      "2018-11-27T12:57:35.368881: step 33, loss 2.46688, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 33/599 (start=2112, end=2176)\n",
      "2018-11-27T12:57:35.666086: step 34, loss 2.64659, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 34/599 (start=2176, end=2240)\n",
      "2018-11-27T12:57:35.960285: step 35, loss 2.63899, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 35/599 (start=2240, end=2304)\n",
      "2018-11-27T12:57:36.253277: step 36, loss 2.48187, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 36/599 (start=2304, end=2368)\n",
      "2018-11-27T12:57:36.534229: step 37, loss 2.69224, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 37/599 (start=2368, end=2432)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-27T12:57:36.826798: step 38, loss 2.42974, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 38/599 (start=2432, end=2496)\n",
      "2018-11-27T12:57:37.121390: step 39, loss 2.38635, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 39/599 (start=2496, end=2560)\n",
      "2018-11-27T12:57:37.409030: step 40, loss 2.5176, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 40/599 (start=2560, end=2624)\n",
      "2018-11-27T12:57:37.686641: step 41, loss 2.56042, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 41/599 (start=2624, end=2688)\n",
      "2018-11-27T12:57:37.979345: step 42, loss 2.36115, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 42/599 (start=2688, end=2752)\n",
      "2018-11-27T12:57:38.280206: step 43, loss 2.59357, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 43/599 (start=2752, end=2816)\n",
      "2018-11-27T12:57:38.565405: step 44, loss 2.57905, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 44/599 (start=2816, end=2880)\n",
      "2018-11-27T12:57:38.847719: step 45, loss 2.39715, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 45/599 (start=2880, end=2944)\n",
      "2018-11-27T12:57:39.145050: step 46, loss 2.37962, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 46/599 (start=2944, end=3008)\n",
      "2018-11-27T12:57:39.413272: step 47, loss 2.81174, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 47/599 (start=3008, end=3072)\n",
      "2018-11-27T12:57:39.712252: step 48, loss 2.45404, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 48/599 (start=3072, end=3136)\n",
      "2018-11-27T12:57:39.982931: step 49, loss 2.3821, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 49/599 (start=3136, end=3200)\n",
      "2018-11-27T12:57:40.287051: step 50, loss 2.76892, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 50/599 (start=3200, end=3264)\n",
      "2018-11-27T12:57:40.573488: step 51, loss 2.67014, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 51/599 (start=3264, end=3328)\n",
      "2018-11-27T12:57:40.866756: step 52, loss 2.60724, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 52/599 (start=3328, end=3392)\n",
      "2018-11-27T12:57:41.131503: step 53, loss 2.49654, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 53/599 (start=3392, end=3456)\n",
      "2018-11-27T12:57:41.425048: step 54, loss 2.38928, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 54/599 (start=3456, end=3520)\n",
      "2018-11-27T12:57:41.707660: step 55, loss 2.57255, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 55/599 (start=3520, end=3584)\n",
      "2018-11-27T12:57:41.986843: step 56, loss 2.65588, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 56/599 (start=3584, end=3648)\n",
      "2018-11-27T12:57:42.257821: step 57, loss 2.45845, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 57/599 (start=3648, end=3712)\n",
      "2018-11-27T12:57:42.535322: step 58, loss 2.51716, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 58/599 (start=3712, end=3776)\n",
      "2018-11-27T12:57:42.824888: step 59, loss 2.62089, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 59/599 (start=3776, end=3840)\n",
      "2018-11-27T12:57:43.119632: step 60, loss 2.46923, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 60/599 (start=3840, end=3904)\n",
      "2018-11-27T12:57:43.409238: step 61, loss 2.36712, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 61/599 (start=3904, end=3968)\n",
      "2018-11-27T12:57:43.684213: step 62, loss 2.55501, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 62/599 (start=3968, end=4032)\n",
      "2018-11-27T12:57:43.960106: step 63, loss 2.27974, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 63/599 (start=4032, end=4096)\n",
      "2018-11-27T12:57:44.245939: step 64, loss 2.67634, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 64/599 (start=4096, end=4160)\n",
      "2018-11-27T12:57:44.528146: step 65, loss 2.55913, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 65/599 (start=4160, end=4224)\n",
      "2018-11-27T12:57:44.806244: step 66, loss 2.39111, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 66/599 (start=4224, end=4288)\n",
      "2018-11-27T12:57:45.107939: step 67, loss 2.64523, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 67/599 (start=4288, end=4352)\n",
      "2018-11-27T12:57:45.375563: step 68, loss 2.4082, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 68/599 (start=4352, end=4416)\n",
      "2018-11-27T12:57:45.678820: step 69, loss 2.2822, acc 0.3125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 69/599 (start=4416, end=4480)\n",
      "2018-11-27T12:57:45.963676: step 70, loss 2.36979, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 70/599 (start=4480, end=4544)\n",
      "2018-11-27T12:57:46.242846: step 71, loss 2.34498, acc 0.3125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 71/599 (start=4544, end=4608)\n",
      "2018-11-27T12:57:46.506704: step 72, loss 2.65174, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 72/599 (start=4608, end=4672)\n",
      "2018-11-27T12:57:46.795307: step 73, loss 2.51987, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 73/599 (start=4672, end=4736)\n",
      "2018-11-27T12:57:47.066689: step 74, loss 2.44853, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 74/599 (start=4736, end=4800)\n",
      "2018-11-27T12:57:47.341039: step 75, loss 2.29372, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 75/599 (start=4800, end=4864)\n",
      "2018-11-27T12:57:47.622661: step 76, loss 2.381, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 76/599 (start=4864, end=4928)\n",
      "2018-11-27T12:57:47.917557: step 77, loss 2.26237, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 77/599 (start=4928, end=4992)\n",
      "2018-11-27T12:57:48.206556: step 78, loss 2.60734, acc 0.15625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 78/599 (start=4992, end=5056)\n",
      "2018-11-27T12:57:48.496310: step 79, loss 2.52639, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 79/599 (start=5056, end=5120)\n",
      "2018-11-27T12:57:48.777410: step 80, loss 2.33154, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 80/599 (start=5120, end=5184)\n",
      "2018-11-27T12:57:49.056595: step 81, loss 2.33808, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 81/599 (start=5184, end=5248)\n",
      "2018-11-27T12:57:49.320851: step 82, loss 2.26135, acc 0.375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 82/599 (start=5248, end=5312)\n",
      "2018-11-27T12:57:49.606514: step 83, loss 2.16404, acc 0.390625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 83/599 (start=5312, end=5376)\n",
      "2018-11-27T12:57:49.894331: step 84, loss 2.41431, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 84/599 (start=5376, end=5440)\n",
      "2018-11-27T12:57:50.165415: step 85, loss 2.36092, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 85/599 (start=5440, end=5504)\n",
      "2018-11-27T12:57:50.465836: step 86, loss 2.5012, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 86/599 (start=5504, end=5568)\n",
      "2018-11-27T12:57:50.731945: step 87, loss 2.36736, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 87/599 (start=5568, end=5632)\n",
      "2018-11-27T12:57:51.003116: step 88, loss 2.33068, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 88/599 (start=5632, end=5696)\n",
      "2018-11-27T12:57:51.300624: step 89, loss 2.75994, acc 0.109375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 89/599 (start=5696, end=5760)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-27T12:57:51.577775: step 90, loss 2.38886, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 90/599 (start=5760, end=5824)\n",
      "2018-11-27T12:57:51.867232: step 91, loss 2.4116, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 91/599 (start=5824, end=5888)\n",
      "2018-11-27T12:57:52.134797: step 92, loss 2.19525, acc 0.40625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 92/599 (start=5888, end=5952)\n",
      "2018-11-27T12:57:52.427404: step 93, loss 2.57176, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 93/599 (start=5952, end=6016)\n",
      "2018-11-27T12:57:52.721489: step 94, loss 2.41464, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 94/599 (start=6016, end=6080)\n",
      "2018-11-27T12:57:53.004868: step 95, loss 2.3357, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 95/599 (start=6080, end=6144)\n",
      "2018-11-27T12:57:53.291113: step 96, loss 2.39123, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 96/599 (start=6144, end=6208)\n",
      "2018-11-27T12:57:53.583199: step 97, loss 2.38877, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 97/599 (start=6208, end=6272)\n",
      "2018-11-27T12:57:53.873683: step 98, loss 2.53394, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 98/599 (start=6272, end=6336)\n",
      "2018-11-27T12:57:54.159671: step 99, loss 2.2357, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 99/599 (start=6336, end=6400)\n",
      "2018-11-27T12:57:54.425250: step 100, loss 2.47904, acc 0.296875\n",
      "\n",
      "Evaluation:\n",
      "2018-11-27T12:57:58.833408: step 100, loss 2.18508, acc 0.392602\n",
      "\n",
      "Saved model checkpoint to /home/jcworkma/jack/w266-group-project_lyric-mood-classification/logs/tf/runs/Em-300_FS-3-4-5_NF-4_D-0.5_L2-0.01_B-64_Ep-10_W2V-1_V-50000/checkpoints/model-100\n",
      "\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 100/599 (start=6400, end=6464)\n",
      "2018-11-27T12:57:59.439046: step 101, loss 2.47043, acc 0.1875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 101/599 (start=6464, end=6528)\n",
      "2018-11-27T12:57:59.714019: step 102, loss 2.39931, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 102/599 (start=6528, end=6592)\n",
      "2018-11-27T12:57:59.989649: step 103, loss 2.39643, acc 0.265625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 103/599 (start=6592, end=6656)\n",
      "2018-11-27T12:58:00.281683: step 104, loss 2.43643, acc 0.203125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 104/599 (start=6656, end=6720)\n",
      "2018-11-27T12:58:00.545095: step 105, loss 2.3519, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 105/599 (start=6720, end=6784)\n",
      "2018-11-27T12:58:00.820226: step 106, loss 2.16475, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 106/599 (start=6784, end=6848)\n",
      "2018-11-27T12:58:01.109358: step 107, loss 2.49824, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 107/599 (start=6848, end=6912)\n",
      "2018-11-27T12:58:01.395938: step 108, loss 2.45579, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 108/599 (start=6912, end=6976)\n",
      "2018-11-27T12:58:01.667045: step 109, loss 2.13182, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 109/599 (start=6976, end=7040)\n",
      "2018-11-27T12:58:01.941694: step 110, loss 2.16356, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 110/599 (start=7040, end=7104)\n",
      "2018-11-27T12:58:02.229084: step 111, loss 2.56243, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 111/599 (start=7104, end=7168)\n",
      "2018-11-27T12:58:02.517963: step 112, loss 2.44837, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 112/599 (start=7168, end=7232)\n",
      "2018-11-27T12:58:02.792555: step 113, loss 2.15611, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 113/599 (start=7232, end=7296)\n",
      "2018-11-27T12:58:03.084041: step 114, loss 2.3833, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 114/599 (start=7296, end=7360)\n",
      "2018-11-27T12:58:03.366837: step 115, loss 2.40955, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 115/599 (start=7360, end=7424)\n",
      "2018-11-27T12:58:03.653751: step 116, loss 2.33171, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 116/599 (start=7424, end=7488)\n",
      "2018-11-27T12:58:03.940772: step 117, loss 2.45166, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 117/599 (start=7488, end=7552)\n",
      "2018-11-27T12:58:04.227881: step 118, loss 2.17564, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 118/599 (start=7552, end=7616)\n",
      "2018-11-27T12:58:04.522418: step 119, loss 2.24176, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 119/599 (start=7616, end=7680)\n",
      "2018-11-27T12:58:04.798949: step 120, loss 2.30118, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 120/599 (start=7680, end=7744)\n",
      "2018-11-27T12:58:05.092144: step 121, loss 2.2987, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 121/599 (start=7744, end=7808)\n",
      "2018-11-27T12:58:05.377609: step 122, loss 2.30951, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 122/599 (start=7808, end=7872)\n",
      "2018-11-27T12:58:05.659519: step 123, loss 2.19066, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 123/599 (start=7872, end=7936)\n",
      "2018-11-27T12:58:05.929486: step 124, loss 2.15287, acc 0.375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 124/599 (start=7936, end=8000)\n",
      "2018-11-27T12:58:06.204096: step 125, loss 2.46428, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 125/599 (start=8000, end=8064)\n",
      "2018-11-27T12:58:06.488921: step 126, loss 2.22296, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 126/599 (start=8064, end=8128)\n",
      "2018-11-27T12:58:06.791290: step 127, loss 2.09025, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 127/599 (start=8128, end=8192)\n",
      "2018-11-27T12:58:07.067781: step 128, loss 2.6996, acc 0.171875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 128/599 (start=8192, end=8256)\n",
      "2018-11-27T12:58:07.361081: step 129, loss 2.27534, acc 0.3125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 129/599 (start=8256, end=8320)\n",
      "2018-11-27T12:58:07.646499: step 130, loss 2.39115, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 130/599 (start=8320, end=8384)\n",
      "2018-11-27T12:58:07.948394: step 131, loss 2.25281, acc 0.3125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 131/599 (start=8384, end=8448)\n",
      "2018-11-27T12:58:08.238365: step 132, loss 2.39201, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 132/599 (start=8448, end=8512)\n",
      "2018-11-27T12:58:08.537017: step 133, loss 2.48983, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 133/599 (start=8512, end=8576)\n",
      "2018-11-27T12:58:08.825326: step 134, loss 2.37707, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 134/599 (start=8576, end=8640)\n",
      "2018-11-27T12:58:09.095450: step 135, loss 2.18279, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 135/599 (start=8640, end=8704)\n",
      "2018-11-27T12:58:09.354007: step 136, loss 2.30886, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 136/599 (start=8704, end=8768)\n",
      "2018-11-27T12:58:09.654920: step 137, loss 2.61547, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 137/599 (start=8768, end=8832)\n",
      "2018-11-27T12:58:09.950097: step 138, loss 2.38431, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 138/599 (start=8832, end=8896)\n",
      "2018-11-27T12:58:10.232803: step 139, loss 2.43927, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 139/599 (start=8896, end=8960)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-27T12:58:10.526148: step 140, loss 2.21829, acc 0.375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 140/599 (start=8960, end=9024)\n",
      "2018-11-27T12:58:10.813899: step 141, loss 2.25188, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 141/599 (start=9024, end=9088)\n",
      "2018-11-27T12:58:11.101620: step 142, loss 2.40184, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 142/599 (start=9088, end=9152)\n",
      "2018-11-27T12:58:11.390372: step 143, loss 2.36509, acc 0.25\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 143/599 (start=9152, end=9216)\n",
      "2018-11-27T12:58:11.684046: step 144, loss 2.36475, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 144/599 (start=9216, end=9280)\n",
      "2018-11-27T12:58:11.980495: step 145, loss 2.46542, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 145/599 (start=9280, end=9344)\n",
      "2018-11-27T12:58:12.273956: step 146, loss 2.28241, acc 0.375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 146/599 (start=9344, end=9408)\n",
      "2018-11-27T12:58:12.565844: step 147, loss 2.45617, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 147/599 (start=9408, end=9472)\n",
      "2018-11-27T12:58:12.842600: step 148, loss 2.28268, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 148/599 (start=9472, end=9536)\n",
      "2018-11-27T12:58:13.117753: step 149, loss 2.22362, acc 0.3125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 149/599 (start=9536, end=9600)\n",
      "2018-11-27T12:58:13.389733: step 150, loss 2.51913, acc 0.21875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 150/599 (start=9600, end=9664)\n",
      "2018-11-27T12:58:13.657379: step 151, loss 2.46814, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 151/599 (start=9664, end=9728)\n",
      "2018-11-27T12:58:13.956373: step 152, loss 2.3052, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 152/599 (start=9728, end=9792)\n",
      "2018-11-27T12:58:14.224827: step 153, loss 2.18414, acc 0.375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 153/599 (start=9792, end=9856)\n",
      "2018-11-27T12:58:14.529394: step 154, loss 2.21246, acc 0.40625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 154/599 (start=9856, end=9920)\n",
      "2018-11-27T12:58:14.816107: step 155, loss 2.28433, acc 0.34375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 155/599 (start=9920, end=9984)\n",
      "2018-11-27T12:58:15.108820: step 156, loss 2.07225, acc 0.421875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 156/599 (start=9984, end=10048)\n",
      "2018-11-27T12:58:15.373301: step 157, loss 2.05984, acc 0.390625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 157/599 (start=10048, end=10112)\n",
      "2018-11-27T12:58:15.664277: step 158, loss 2.40766, acc 0.28125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 158/599 (start=10112, end=10176)\n",
      "2018-11-27T12:58:15.949228: step 159, loss 2.25894, acc 0.328125\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 159/599 (start=10176, end=10240)\n",
      "2018-11-27T12:58:16.237102: step 160, loss 2.4646, acc 0.296875\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 160/599 (start=10240, end=10304)\n",
      "2018-11-27T12:58:16.535122: step 161, loss 2.26937, acc 0.234375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 161/599 (start=10304, end=10368)\n",
      "2018-11-27T12:58:16.832726: step 162, loss 2.2063, acc 0.359375\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 162/599 (start=10368, end=10432)\n",
      "2018-11-27T12:58:17.124582: step 163, loss 2.05908, acc 0.40625\n",
      "-----------------------------------------------\n",
      "Epoch 0/10, Batch 163/599 (start=10432, end=10496)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-2e5b202ce0b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlyrics_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-40-a5c01848c52d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(vocab_size, x_train, y_train, x_dev, y_dev, x_test, y_test, train_embeddings, embeddings)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                 \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_summary_writer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_writer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcsvwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0mcurrent_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcurrent_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mevaluate_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-a5c01848c52d>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(x_batch, y_batch, summary_writer, step_writer)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 _, step, summaries, loss, accuracy = sess.run(\n\u001b[1;32m    160\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_summary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     feed_dict)\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0mtime_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misoformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}: step {}, loss {:g}, acc {:g}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jack/w266-group-project_lyric-mood-classification/.venv_w266_project/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "V = lyrics2vec.VOCAB_SIZE\n",
    "#V = 50000\n",
    "# need to convert lyrics into numpy 2d arrays\n",
    "# need to convert classes into dummies\n",
    "train_embeddings = False\n",
    "\n",
    "train(\n",
    "    vocab_size=V,\n",
    "    x_train=np.array(list(df_train.normalized_lyrics)),\n",
    "    y_train=pd.get_dummies(df_train.mood).values,\n",
    "    x_dev=np.array(list(df_dev.normalized_lyrics)),\n",
    "    y_dev=pd.get_dummies(df_dev.mood).values,\n",
    "    x_test=np.array(list(df_test.normalized_lyrics)),\n",
    "    y_test=pd.get_dummies(df_test.mood).values,\n",
    "    train_embeddings=train_embeddings,\n",
    "    embeddings=lyrics_vectorizer.final_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments\n",
    "\n",
    "Reigning Champion: w2v0\n",
    "\n",
    "batch_size of 32 speeds up training but doesn't impact scalars too much  \n",
    "L2 has impact - kind of judged that .01 is the best  \n",
    "Embedding size - 300 > 128 for word2vec; no word2vec 128 still reigns supreme\n",
    "\n",
    "Open questions:\n",
    "* vocab size adjustments? currently a lot of nonsense words are in there - would we be more more accurate if we removed those?\n",
    "* word embeddings - lots of experiments to run there\n",
    "* dropout rate\n",
    "* Can we make a full pipeline that trains word embeddings based on params then uses word embedding to train model based on params then analyses results to find best loss+accuracy point and save accuracy? Then we could let 100 experiments go in a day and see what happens\n",
    "* concatenate word2vec with untrained embeddings\n",
    "* word2vec trainable\n",
    "\n",
    "Using expanded dataset with w2v0 and standard settings yielded test acc of ~52. Loss begin climbing at 4.5k steps at which point acc was ~50. Will drop epoch to 10 as steps went to 12k and 6k should be enough to see improvement. Trying again with w2v1.\n",
    "\n",
    "Three things:\n",
    "\n",
    "1. Build complete experimental pipeline\n",
    "2. dethrone chill as king of moods\n",
    "3. improve word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_w266_project",
   "language": "python",
   "name": ".venv_w266_project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
